================================================================================
vLLM CROSS-HARDWARE BATCH SIZE DETECTABILITY - GENERATION (decode)
================================================================================

System: c6ba2aea0d91
GPU: NVIDIA H100 80GB HBM3
vLLM: 0.11.2
PyTorch: 2.9.0+cu128
CUDA: 12.8

Configuration:
  Model: Qwen/Qwen2.5-7B-Instruct
  Batch sizes: [1, 2, 3, 4, 5, 8, 9]
  Max tokens: 20
  Top-k logprobs: 20

Loading vLLM model...
✓ Model loaded

Found 1 PDF(s)
  Loading: /workspace/Verification-for-International-AI-Governance.pdf
    → 120214 tokens
Total tokens: 120214
Creating 27 slices of 200 tokens each
Created 3 reference sequences


================================================================================
REFERENCE: ref_0
================================================================================

Global minimum prompt length: 200 tokens

  bs=1:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=2:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=3:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=4:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=5:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=8:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=9:       Prompt: 200 tokens → Final: 220 tokens (20 generated)

================================================================================
REFERENCE: ref_1
================================================================================

Global minimum prompt length: 200 tokens

  bs=1:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=2:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=3:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=4:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=5:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=8:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=9:       Prompt: 200 tokens → Final: 220 tokens (20 generated)

================================================================================
REFERENCE: ref_2
================================================================================

Global minimum prompt length: 200 tokens

  bs=1:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=2:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=3:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=4:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=5:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=8:       Prompt: 200 tokens → Final: 220 tokens (20 generated)
  bs=9:       Prompt: 200 tokens → Final: 220 tokens (20 generated)

✓ Generation results saved to: /workspace/experiments/vllm_decode_20251126_001933.json

--- Token consistency for ref_0 ---

================================================================================
TOKEN GENERATION CONSISTENCY CHECK
================================================================================

Generated tokens by batch size:
  bs=1:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=2:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=3:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=4:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=5:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=8:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓
  bs=9:
    IDs:  [2571, 8199, 42, 20175, 440, 17, 19, 11, 2016, 344, 5559, 50, 76367, 559, 2907, 17, 20, 11, 17, 21]
    Text: 'lexanderKatzke24,ShivaniSrivastava25,26'
    ✓

✓ Element 0 generates IDENTICAL tokens across all batch sizes

--- Token consistency for ref_1 ---

================================================================================
TOKEN GENERATION CONSISTENCY CHECK
================================================================================

Generated tokens by batch size:
  bs=1:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=2:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=3:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=4:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=5:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=8:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓
  bs=9:
    IDs:  [659, 659, 659, 659, 659, 220, 20, 20, 198, 17, 13, 18, 13, 16, 7420, 9471, 659, 659, 659, 659]
    Text: ' . . . . . 55\n2.3.1 Power generation . . . .'
    ✓

✓ Element 0 generates IDENTICAL tokens across all batch sizes

--- Token consistency for ref_2 ---

================================================================================
TOKEN GENERATION CONSISTENCY CHECK
================================================================================

Generated tokens by batch size:
  bs=1:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=2:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=3:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=4:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=5:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=8:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓
  bs=9:
    IDs:  [22901, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659]
    Text: ' verification . . . . . . . . . . . . . . . . . . .'
    ✓

✓ Element 0 generates IDENTICAL tokens across all batch sizes

================================================================================
WITHIN-HARDWARE BATCH SIZE EFFECTS (PREFILL)
================================================================================

ref_0:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=2    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=3    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=4    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=5    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=8    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00
bs=9    0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00

ref_1:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.55e-01  0.00e+00  1.55e-01
bs=2    0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.55e-01  0.00e+00  1.55e-01
bs=3    0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.55e-01  0.00e+00  1.55e-01
bs=4    0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.55e-01  0.00e+00  1.55e-01
bs=5    1.55e-01  1.55e-01  1.55e-01  1.55e-01  0.00e+00  1.55e-01  0.00e+00
bs=8    0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.55e-01  0.00e+00  1.55e-01
bs=9    1.55e-01  1.55e-01  1.55e-01  1.55e-01  0.00e+00  1.55e-01  0.00e+00

ref_2:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  0.00e+00  1.31e-01  1.31e-01  1.31e-01  0.00e+00  0.00e+00
bs=2    0.00e+00  0.00e+00  1.31e-01  1.31e-01  1.31e-01  0.00e+00  0.00e+00
bs=3    1.31e-01  1.31e-01  0.00e+00  0.00e+00  0.00e+00  1.31e-01  1.31e-01
bs=4    1.31e-01  1.31e-01  0.00e+00  0.00e+00  0.00e+00  1.31e-01  1.31e-01
bs=5    1.31e-01  1.31e-01  0.00e+00  0.00e+00  0.00e+00  1.31e-01  1.31e-01
bs=8    0.00e+00  0.00e+00  1.31e-01  1.31e-01  1.31e-01  0.00e+00  0.00e+00
bs=9    0.00e+00  0.00e+00  1.31e-01  1.31e-01  1.31e-01  0.00e+00  0.00e+00

================================================================================
AGGREGATE (average across references):
================================================================================
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  0.00e+00  4.36e-02  4.36e-02  9.54e-02  0.00e+00  5.18e-02
bs=2    0.00e+00  0.00e+00  4.36e-02  4.36e-02  9.54e-02  0.00e+00  5.18e-02
bs=3    4.36e-02  4.36e-02  0.00e+00  0.00e+00  5.18e-02  4.36e-02  9.54e-02
bs=4    4.36e-02  4.36e-02  0.00e+00  0.00e+00  5.18e-02  4.36e-02  9.54e-02
bs=5    9.54e-02  9.54e-02  5.18e-02  5.18e-02  0.00e+00  9.54e-02  4.36e-02
bs=8    0.00e+00  0.00e+00  4.36e-02  4.36e-02  9.54e-02  0.00e+00  5.18e-02
bs=9    5.18e-02  5.18e-02  9.54e-02  9.54e-02  4.36e-02  5.18e-02  0.00e+00

Off-diagonal stats:
  Mean: 4.96e-02
  Range: [0.00e+00, 9.54e-02]

⚠ NOTE: 4/21 comparisons are equivalent (< 1e-09)

Kernel equivalence classes:
  Class 1: [1, 2, 8]
  Class 2: [3, 4]
  Class 3: [5]
  Class 4: [9]

Equivalent pairs (will be excluded from cross-hardware signal):
  (1, 2)
  (1, 8)
  (2, 8)
  (3, 4)

================================================================================
WITHIN-HARDWARE BATCH SIZE EFFECTS (DECODE)
================================================================================

ref_0:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  1.08e-01  9.34e-02  9.34e-02  9.34e-02  9.34e-02  3.81e-02
bs=2    1.08e-01  0.00e+00  6.88e-02  6.88e-02  6.88e-02  6.88e-02  1.26e-01
bs=3    9.34e-02  6.88e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.06e-01
bs=4    9.34e-02  6.88e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.06e-01
bs=5    9.34e-02  6.88e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.06e-01
bs=8    9.34e-02  6.88e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.06e-01
bs=9    3.81e-02  1.26e-01  1.06e-01  1.06e-01  1.06e-01  1.06e-01  0.00e+00

ref_1:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  1.74e-01  1.05e-01  1.05e-01  7.98e-02  1.05e-01  1.18e-01
bs=2    1.74e-01  0.00e+00  1.60e-01  1.60e-01  1.79e-01  1.60e-01  1.42e-01
bs=3    1.05e-01  1.60e-01  0.00e+00  0.00e+00  1.58e-01  0.00e+00  1.75e-01
bs=4    1.05e-01  1.60e-01  0.00e+00  0.00e+00  1.58e-01  0.00e+00  1.75e-01
bs=5    7.98e-02  1.79e-01  1.58e-01  1.58e-01  0.00e+00  1.58e-01  1.19e-01
bs=8    1.05e-01  1.60e-01  0.00e+00  0.00e+00  1.58e-01  0.00e+00  1.75e-01
bs=9    1.18e-01  1.42e-01  1.75e-01  1.75e-01  1.19e-01  1.75e-01  0.00e+00

ref_2:
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  1.14e-01  1.14e-01  9.27e-02  9.27e-02  9.76e-02  1.51e-01
bs=2    1.14e-01  0.00e+00  8.83e-02  2.95e-02  2.95e-02  7.60e-02  6.74e-02
bs=3    1.14e-01  8.83e-02  0.00e+00  6.25e-02  6.25e-02  9.27e-02  1.01e-01
bs=4    9.27e-02  2.95e-02  6.25e-02  0.00e+00  0.00e+00  7.60e-02  6.74e-02
bs=5    9.27e-02  2.95e-02  6.25e-02  0.00e+00  0.00e+00  7.60e-02  6.74e-02
bs=8    9.76e-02  7.60e-02  9.27e-02  7.60e-02  7.60e-02  0.00e+00  1.18e-01
bs=9    1.51e-01  6.74e-02  1.01e-01  6.74e-02  6.74e-02  1.18e-01  0.00e+00

================================================================================
AGGREGATE (average across references):
================================================================================
       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 
bs=1    0.00e+00  1.32e-01  1.04e-01  9.69e-02  8.86e-02  9.85e-02  1.02e-01
bs=2    1.32e-01  0.00e+00  1.06e-01  8.60e-02  9.25e-02  1.02e-01  1.12e-01
bs=3    1.04e-01  1.06e-01  0.00e+00  2.08e-02  7.35e-02  3.09e-02  1.28e-01
bs=4    9.69e-02  8.60e-02  2.08e-02  0.00e+00  5.27e-02  2.53e-02  1.16e-01
bs=5    8.86e-02  9.25e-02  7.35e-02  5.27e-02  0.00e+00  7.80e-02  9.77e-02
bs=8    9.85e-02  1.02e-01  3.09e-02  2.53e-02  7.80e-02  0.00e+00  1.33e-01
bs=9    1.02e-01  1.12e-01  1.28e-01  1.16e-01  9.77e-02  1.33e-01  0.00e+00

Off-diagonal stats:
  Mean: 8.93e-02
  Range: [2.08e-02, 1.33e-01]

Kernel equivalence classes:
  Class 1: [1]
  Class 2: [2]
  Class 3: [3]
  Class 4: [4]
  Class 5: [5]
  Class 6: [8]
  Class 7: [9]

Next step: Copy /workspace/experiments/vllm_decode_20251126_001933.json to verifier machine
Then set TEACHER_FORCING = True and REFERENCE_FILE = '<path>'
File size: 0.5 MB

================================================================================
EXPERIMENT COMPLETE
================================================================================

