{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fb9e08-8680-473f-b415-54312ed3069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-HARDWARE BATCH SIZE DETECTABILITY - GENERATION (reference)\n",
      "================================================================================\n",
      "\n",
      "System: c6c6242ae438\n",
      "GPU: NVIDIA A100 80GB PCIe\n",
      "Attention: sdpa\n",
      "Layers: [28]\n",
      "Found 2 PDF(s)\n",
      "  Loading: /workspace/Llama3.1.pdf\n",
      "  Loading: /workspace/Verification-for-International-AI-Governance.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (219497 > 131072). Running this sequence through the model will result in indexing errors\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total source tokens: 219497\n",
      "Prompt structure: 33 prefix + 3000 snippet + 34 suffix = 3067 tokens\n",
      "All 51 prompts: 3067 tokens each\n",
      "\n",
      "Sample prompt ending:\n",
      "' To do this effectively, pre\"\\n\\nBased on this excerpt, what type of document do you think this is from, and what is its likely subject matter? Explain your reasoning.<|im_end|>\\n<|im_start|>assistant\\n'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5914b4dc644531a77ed9cc21920c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REFERENCE: ref_0\n",
      "================================================================================\n",
      "\n",
      "Prompt length: 3067 tokens\n",
      "\n",
      "  bs=1:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=2:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=3:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=4:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=5:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=8:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=9:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=16:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=17:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "\n",
      "================================================================================\n",
      "REFERENCE: ref_1\n",
      "================================================================================\n",
      "\n",
      "Prompt length: 3067 tokens\n",
      "\n",
      "  bs=1:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=2:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=3:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=4:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=5:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=8:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=9:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=16:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=17:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "\n",
      "================================================================================\n",
      "REFERENCE: ref_2\n",
      "================================================================================\n",
      "\n",
      "Prompt length: 3067 tokens\n",
      "\n",
      "  bs=1:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=2:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=3:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=4:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=5:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=8:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=9:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=16:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "  bs=17:      Prompt: 3067 tokens → Final: 3217 tokens (150 generated)\n",
      "\n",
      "--- Token consistency for ref_0 ---\n",
      "\n",
      "================================================================================\n",
      "TOKEN GENERATION CONSISTENCY CHECK\n",
      "================================================================================\n",
      "\n",
      "Generated tokens by batch size:\n",
      "  bs=1:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 5435, 311, 15235, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 85370, 2217, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481, 576, 2197, 5707, 16376, 10916, 3565, 911]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts related to AI, such as \"Transformer,\" \"FLOPs,\" and \"pre-training.\"\\n\\n2. **Technical Details:**\\n   - The document provides extensive technical details about'\n",
      "    ✓\n",
      "  bs=2:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 69193, 1335, 892, 525, 4185, 304, 15235, 323, 5662, 6832, 17206, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-processing,\" which are common in AI and machine learning literature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=3:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 85370, 1335, 892, 525, 4185, 304, 15235, 3412, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481, 576, 2197, 5707]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-training,\" which are common in AI research.\\n\\n2. **Technical Details:**\\n   - The document provides'\n",
      "    ✗ DIFFERENT\n",
      "  bs=4:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 85370, 1335, 892, 525, 4185, 304, 15235, 323, 5662, 6832, 17206, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-training,\" which are common in AI and machine learning literature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=5:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 5435, 311, 15235, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 93052, 6872, 1335, 18860, 264, 10916, 323, 14250, 6993, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts related to AI, such as \"Transformer,\" \"FLOPs,\" and \"scaling laws,\" indicating a technical and academic nature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=8:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 69193, 1335, 892, 525, 4185, 304, 15235, 323, 5662, 6832, 17206, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-processing,\" which are common in AI and machine learning literature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=9:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 69193, 1335, 892, 525, 4185, 304, 15235, 323, 5662, 6832, 17206, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-processing,\" which are common in AI and machine learning literature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=16:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 33845, 3151, 10916, 3793, 323, 18940, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 85370, 1335, 892, 525, 4185, 304, 15235, 323, 5662, 6832, 17206, 382, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document mentions specific technical terms and concepts, such as \"Transformer,\" \"FLOPs,\" and \"pre-training,\" which are common in AI and machine learning literature.\\n\\n2. **Technical Details:**\\n   -'\n",
      "    ✗ DIFFERENT\n",
      "  bs=17:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 5567, 476, 10916, 1895, 11, 4363, 10735, 389, 279, 4401, 323, 16460, 315, 264, 501, 738, 315, 16266, 4119, 2598, 444, 80001, 220, 18, 13, 576, 2197, 594, 3832, 4925, 374, 30188, 2163, 20443, 11229, 11, 11689, 3460, 4128, 4119, 323, 862, 8357, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 7524, 28596, 323, 8883, 25, 1019, 256, 481, 576, 2197, 12033, 448, 458, 16800, 311, 279, 444, 80001, 220, 18, 4119, 11, 44193, 862, 16928, 323, 5068, 624, 256, 481, 1084, 5646, 264, 11682, 29985, 315, 279, 4119, 6, 17646, 11, 4862, 1882, 11, 323, 16460, 16734, 624, 256, 481, 576, 2197, 15057, 3151, 10916, 3793, 323, 18940, 5435, 311, 15235, 11, 1741, 438, 330, 46358, 1335, 330, 37, 1593, 20420, 1335, 323, 330, 1726, 85370, 2217, 17, 13, 3070, 62226, 12309, 25, 1019, 256, 481, 576, 2197, 5707, 3151, 10916, 3565, 911]\n",
      "    Text: 'This excerpt is from a research paper or technical report, likely focused on the development and evaluation of a new set of foundation models called Llama 3. The document\\'s subject matter is centered around artificial intelligence, specifically large language models and their applications.\\n\\n### Reasoning:\\n\\n1. **Document Structure and Content:**\\n   - The document begins with an introduction to the Llama 3 models, detailing their capabilities and performance.\\n   - It includes a detailed breakdown of the models\\' architecture, training process, and evaluation metrics.\\n   - The document references specific technical terms and concepts related to AI, such as \"Transformer,\" \"FLOPs,\" and \"pre-training.\"\\n\\n2. **Technical Details:**\\n   - The document provides specific technical details about'\n",
      "    ✗ DIFFERENT\n",
      "\n",
      "⚠ Element 0 generates DIFFERENT tokens across batch sizes\n",
      "\n",
      "--- Token consistency for ref_1 ---\n",
      "\n",
      "================================================================================\n",
      "TOKEN GENERATION CONSISTENCY CHECK\n",
      "================================================================================\n",
      "\n",
      "Generated tokens by batch size:\n",
      "  bs=1:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 17646, 11, 323, 22000, 6505, 369, 53852, 11129, 323, 4128, 8692, 1119, 264, 1614, 2598, 444, 80001, 220, 18, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 25771, 287, 95518, 576, 49465, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 80798, 11, 892, 525, 14260, 315, 10916, 3412, 9293, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 17590, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 5662, 6832, 11, 1380, 279, 1614, 646, 1882, 2176, 1467]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, architecture, and experimental setup for integrating vision and language processing into a model called Llama 3.\\n\\n### Reasoning:\\n\\n1. **Technical Detailing**: The excerpt contains detailed descriptions of data processing pipelines, model architectures, and training methodologies, which are typical of technical research documents.\\n\\n2. **Multimodal Model**: The document discusses the integration of visual recognition capabilities into a language model, indicating a focus on multimodal machine learning, where the model can process both text'\n",
      "    ✓\n",
      "  bs=2:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 264, 4158, 5567, 11, 14250, 5567, 11, 476, 264, 10916, 1895, 13, 576, 3832, 4925, 374, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 18250, 9124, 17843, 16928, 11, 13862, 311, 438, 444, 80001, 220, 18, 13, 5692, 594, 279, 32711, 4815, 419, 16688, 1447, 16, 13, 3070, 62226, 25771, 323, 45945, 2449, 95518, 576, 2197, 5610, 11682, 10916, 1995, 323, 3151, 56626, 5435, 311, 5662, 6832, 11, 1741, 438, 330, 13013, 42578, 1335, 330, 28842, 12, 53103, 13617, 1335, 330, 1805, 23668, 1335, 323, 330, 3888, 9819, 96680, 13617, 1189, 1096, 14807, 429, 279, 2197, 374, 19469, 518, 458, 10650, 448, 264, 10916, 4004, 382, 17, 13, 3070, 1712, 10816, 323, 16151, 95518, 576, 49465, 34334, 279, 4401, 323, 4862, 1882, 315, 264, 79049, 57597, 1614]\n",
      "    Text: 'This excerpt is from a research or technical document, likely a white paper, academic paper, or a technical report. The subject matter is the development and training of a multimodal model, specifically a large language model (LLM) with integrated visual recognition capabilities, referred to as Llama 3. Here\\'s the reasoning behind this conclusion:\\n\\n1. **Technical Detail and Terminology**: The document contains detailed technical information and specific terminology related to machine learning, such as \"vision transformer,\" \"cross-attention layers,\" \"image encoder,\" and \"temporal aggregator layers.\" This indicates that the document is aimed at an audience with a technical background.\\n\\n2. **Model Development and Training**: The excerpt discusses the development and training process of a multimodal model'\n",
      "    ✗ DIFFERENT\n",
      "  bs=3:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 17646, 11, 323, 22000, 6505, 369, 53852, 11129, 323, 4128, 8692, 304, 264, 1614, 2598, 444, 80001, 220, 18, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 25771, 287, 95518, 576, 49465, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 80798, 13, 1096, 2188, 315, 10916, 7716, 374, 28583, 315, 3412, 476, 10916, 9705, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 17590, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 892, 374, 264, 4185, 8544, 304, 79049, 57597, 5662, 6832, 3412]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, architecture, and experimental setup for integrating vision and language processing in a model called Llama 3.\\n\\n### Reasoning:\\n\\n1. **Technical Detailing**: The excerpt contains detailed descriptions of data processing pipelines, model architectures, and training methodologies. This level of technical detail is characteristic of research or technical documentation.\\n\\n2. **Multimodal Model**: The document discusses the integration of visual recognition capabilities into a language model, which is a common topic in multimodal machine learning research'\n",
      "    ✗ DIFFERENT\n",
      "  bs=4:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 821, 11, 323, 17646, 315, 279, 1614, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 21331, 95518, 576, 2197, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 80798, 11, 892, 525, 14260, 315, 10916, 3412, 15689, 476, 9705, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 1467, 34334, 279, 17590, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 5662, 6832, 13, 1096, 374, 264, 1482, 3082, 315, 3412, 304, 15235, 11, 1380, 4119, 525, 6188, 311, 1882, 323, 3535]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, data, and architecture of the model.\\n\\n### Reasoning:\\n\\n1. **Technical Nature**: The document contains detailed descriptions of data processing pipelines, model architectures, and training methodologies, which are typical of technical research papers or documentation.\\n\\n2. **Multimodal Model**: The text discusses the integration of visual recognition capabilities into a language model, indicating a focus on multimodal machine learning. This is a current area of research in AI, where models are designed to process and understand'\n",
      "    ✗ DIFFERENT\n",
      "  bs=5:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 17646, 11, 323, 22000, 6505, 369, 53852, 11129, 323, 4128, 8692, 1119, 264, 1614, 2598, 444, 80001, 220, 18, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 25771, 287, 95518, 576, 49465, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 80798, 11, 892, 525, 14260, 315, 10916, 3412, 9293, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 17590, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 5662, 6832, 11, 1380, 279, 1614, 646, 1882, 2176, 1467]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, architecture, and experimental setup for integrating vision and language processing into a model called Llama 3.\\n\\n### Reasoning:\\n\\n1. **Technical Detailing**: The excerpt contains detailed descriptions of data processing pipelines, model architectures, and training methodologies, which are typical of technical research documents.\\n\\n2. **Multimodal Model**: The document discusses the integration of visual recognition capabilities into a language model, indicating a focus on multimodal machine learning, where the model can process both text'\n",
      "    ✓\n",
      "  bs=8:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 821, 11, 323, 17646, 315, 279, 1614, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 45945, 2449, 323, 75772, 334, 510, 256, 481, 576, 2197, 5711, 10916, 3793, 1741, 438, 330, 13013, 42578, 320, 35544, 51, 35393, 330, 28842, 12, 53103, 13617, 1335, 330, 1805, 23668, 1335, 330, 9986, 12956, 1335, 323, 330, 3888, 9819, 96680, 1335, 892, 525, 4185, 304, 5662, 6832, 323, 6366, 11129, 17206, 624, 256, 481, 1084, 34334, 279, 4862, 1882, 11, 2670, 821, 63631, 11, 1614, 17646, 11, 323, 4862, 14830, 11, 18860, 264, 10916, 323, 3412, 35085]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, data, and architecture of the model.\\n\\n### Reasoning:\\n\\n1. **Technical Terminology and Concepts**:\\n   - The document uses technical terms such as \"vision transformer (ViT),\" \"cross-attention layers,\" \"image encoder,\" \"video adapter,\" and \"temporal aggregator,\" which are common in machine learning and computer vision literature.\\n   - It discusses the training process, including data preprocessing, model architecture, and training strategies, indicating a technical and research-oriented'\n",
      "    ✗ DIFFERENT\n",
      "  bs=9:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 821, 11, 323, 17646, 315, 279, 1614, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 21331, 95518, 576, 1467, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 15966, 11, 892, 525, 14260, 315, 10916, 9293, 304, 279, 2070, 315, 5662, 6832, 323, 20443, 11229, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 87365, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 6832, 11, 892, 374, 264, 1376, 3082, 315, 3412, 304, 15235, 382, 18, 13, 3070]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, data, and architecture of the model.\\n\\n### Reasoning:\\n\\n1. **Technical Nature**: The text contains detailed descriptions of data processing pipelines, model architectures, and training procedures, which are typical of technical documents in the field of machine learning and artificial intelligence.\\n\\n2. **Multimodal Model**: The document discusses the incorporation of visual recognition capabilities into a language model, indicating a focus on multimodal learning, which is a key area of research in AI.\\n\\n3. **'\n",
      "    ✗ DIFFERENT\n",
      "  bs=16:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 821, 11, 323, 17646, 315, 279, 1614, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 21331, 95518, 576, 1467, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 15966, 11, 892, 525, 14260, 315, 10916, 9293, 304, 279, 2070, 315, 5662, 6832, 323, 20443, 11229, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 17590, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 6832, 11, 892, 374, 264, 1376, 3082, 315, 3412, 304, 15235, 382, 18, 13, 3070]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, data, and architecture of the model.\\n\\n### Reasoning:\\n\\n1. **Technical Nature**: The text contains detailed descriptions of data processing pipelines, model architectures, and training procedures, which are typical of technical documents in the field of machine learning and artificial intelligence.\\n\\n2. **Multimodal Model**: The document discusses the integration of visual recognition capabilities into a language model, indicating a focus on multimodal learning, which is a key area of research in AI.\\n\\n3. **'\n",
      "    ✗ DIFFERENT\n",
      "  bs=17:\n",
      "    IDs:  [1986, 49465, 374, 504, 264, 3412, 476, 10916, 2197, 11, 4363, 5435, 311, 279, 4401, 323, 4862, 315, 264, 79049, 57597, 5662, 6832, 1614, 11, 11689, 264, 3460, 4128, 1614, 320, 4086, 44, 8, 448, 3694, 9124, 17843, 16928, 13, 576, 2197, 7952, 311, 387, 949, 315, 264, 8131, 1895, 476, 5567, 44193, 279, 37052, 11, 821, 11, 323, 17646, 315, 279, 1614, 382, 14374, 26759, 287, 1447, 16, 13, 3070, 62226, 21331, 95518, 576, 1467, 5610, 11682, 27787, 315, 821, 8692, 57673, 11, 1614, 77235, 11, 323, 4862, 15966, 11, 892, 525, 14260, 315, 10916, 9293, 304, 279, 2070, 315, 5662, 6832, 323, 20443, 11229, 382, 17, 13, 3070, 40404, 318, 57597, 4903, 95518, 576, 2197, 34334, 279, 87365, 315, 9124, 17843, 16928, 1119, 264, 4128, 1614, 11, 18860, 264, 5244, 389, 79049, 57597, 320, 1318, 323, 2168, 41303, 8, 8692, 13, 1096, 374, 264, 4185, 3082, 315, 3412]\n",
      "    Text: 'This excerpt is from a research or technical document, likely related to the development and training of a multimodal machine learning model, specifically a large language model (LLM) with added visual recognition capabilities. The document appears to be part of a larger report or paper detailing the methodology, data, and architecture of the model.\\n\\n### Reasoning:\\n\\n1. **Technical Nature**: The text contains detailed descriptions of data processing pipelines, model architectures, and training procedures, which are typical of technical documents in the field of machine learning and artificial intelligence.\\n\\n2. **Multimodal Model**: The document discusses the incorporation of visual recognition capabilities into a language model, indicating a focus on multimodal (text and image/video) processing. This is a common area of research'\n",
      "    ✗ DIFFERENT\n",
      "\n",
      "⚠ Element 0 generates DIFFERENT tokens across batch sizes\n",
      "\n",
      "--- Token consistency for ref_2 ---\n",
      "\n",
      "================================================================================\n",
      "TOKEN GENERATION CONSISTENCY CHECK\n",
      "================================================================================\n",
      "\n",
      "Generated tokens by batch size:\n",
      "  bs=1:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2197, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The document delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✓\n",
      "  bs=2:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2197, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The document delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✓\n",
      "  bs=3:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 6540, 8317, 11, 5101, 8317, 11, 74410, 4963, 11, 12851, 10030, 2090, 11, 323, 19256, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2213, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11, 8317]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as knowledge transfer, resource transfer, pooling resources, emergency preparedness, and regulation. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The content delves into technical and policy aspects of AI governance, including verification requirements, transfer'\n",
      "    ✗ DIFFERENT\n",
      "  bs=4:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2197, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The document delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✓\n",
      "  bs=5:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 6540, 8317, 11, 5101, 8317, 11, 74410, 4963, 11, 12851, 10030, 2090, 11, 323, 19256, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2213, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11, 8317]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as knowledge transfer, resource transfer, pooling resources, emergency preparedness, and regulation. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The content delves into technical and policy aspects of AI governance, including verification requirements, transfer'\n",
      "    ✗ DIFFERENT\n",
      "  bs=8:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2197, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The document delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✓\n",
      "  bs=9:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 6540, 8317, 11, 5101, 8317, 11, 74410, 4963, 11, 12851, 10030, 2090, 11, 323, 19256, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2213, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11, 8317]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as knowledge transfer, resource transfer, pooling resources, emergency preparedness, and regulation. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The content delves into technical and policy aspects of AI governance, including verification requirements, transfer'\n",
      "    ✗ DIFFERENT\n",
      "  bs=16:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2197, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The document delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✓\n",
      "  bs=17:\n",
      "    IDs:  [28715, 389, 279, 49465, 3897, 11, 419, 2197, 7952, 311, 387, 504, 264, 1895, 476, 4158, 5567, 10735, 389, 279, 6489, 34086, 323, 22901, 315, 20443, 11229, 320, 15469, 8, 19473, 13, 576, 2197, 34334, 5257, 13566, 315, 15235, 34086, 11, 2670, 279, 8317, 315, 6540, 323, 4963, 11, 74410, 315, 4963, 11, 17975, 369, 67974, 11, 323, 19256, 13, 5692, 525, 279, 1376, 3501, 429, 1824, 419, 16688, 1447, 16, 13, 3070, 22952, 323, 8883, 95518, 576, 2197, 374, 16645, 1119, 14158, 429, 4263, 2155, 4494, 315, 6489, 19473, 5435, 311, 15235, 11, 1741, 438, 49951, 6540, 11, 49951, 4963, 11, 74410, 4963, 11, 20045, 369, 67974, 11, 323, 57399, 15235, 13, 1096, 5944, 374, 14260, 315, 264, 11682, 1895, 476, 4158, 5567, 382, 17, 13, 3070, 62226, 323, 10974, 25806, 95518, 576, 2213, 1594, 2342, 1119, 10916, 323, 4842, 13566, 315, 15235, 34086, 11, 2670, 22901, 8502, 11]\n",
      "    Text: 'Based on the excerpt provided, this document appears to be from a report or white paper focused on the international governance and verification of artificial intelligence (AI) agreements. The document discusses various aspects of AI governance, including the transfer of knowledge and resources, pooling of resources, preparation for emergencies, and regulation. Here are the key points that support this conclusion:\\n\\n1. **Structure and Content**: The document is organized into sections that discuss different types of international agreements related to AI, such as transferring knowledge, transferring resources, pooling resources, preparing for emergencies, and regulating AI. This structure is typical of a detailed report or white paper.\\n\\n2. **Technical and Policy Focus**: The content delves into technical and policy aspects of AI governance, including verification requirements,'\n",
      "    ✗ DIFFERENT\n",
      "\n",
      "⚠ Element 0 generates DIFFERENT tokens across batch sizes\n",
      "\n",
      "================================================================================\n",
      "WITHIN-HARDWARE BATCH SIZE EFFECTS (PREFILL)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "REF_0\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  5.01e-01  5.01e-01  5.01e-01  5.01e-01  5.01e-01  5.01e-01  5.01e-01  5.01e-01\n",
      "bs=2    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   5.01e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.04e-01  4.04e-01  4.04e-01  4.04e-01  4.04e-01  4.04e-01  4.04e-01  4.04e-01\n",
      "bs=2    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.04e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "REF_1\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.60e-01  4.60e-01  4.60e-01  4.60e-01  4.60e-01  4.60e-01  4.60e-01  4.60e-01\n",
      "bs=2    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.60e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.97e-01  4.97e-01  4.97e-01  4.97e-01  4.97e-01  4.97e-01  4.97e-01  4.97e-01\n",
      "bs=2    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.97e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "REF_2\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.80e-01  4.80e-01  4.80e-01  4.80e-01  4.80e-01  4.80e-01  4.80e-01  4.80e-01\n",
      "bs=2    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  3.49e-01  3.49e-01  3.49e-01  3.49e-01  3.49e-01  3.49e-01  3.49e-01  3.49e-01\n",
      "bs=2    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   3.45e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "AGGREGATE (average across references):\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.81e-01  4.81e-01  4.81e-01  4.81e-01  4.81e-01  4.81e-01  4.81e-01  4.81e-01\n",
      "bs=2    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.81e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  4.16e-01  4.16e-01  4.16e-01  4.16e-01  4.16e-01  4.16e-01  4.16e-01  4.16e-01\n",
      "bs=2    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=3    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=4    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=5    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=8    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=9    4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=16   4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "bs=17   4.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "\n",
      "Off-diagonal stats:\n",
      "  Key vectors - Mean: 1.07e-01, Range: [0.00e+00, 4.81e-01]\n",
      "  Logprobs - Mean: 9.25e-02, Range: [0.00e+00, 4.16e-01]\n",
      "\n",
      "⚠ NOTE: 28/36 comparisons are equivalent (< 1e-09)\n",
      "\n",
      "Kernel equivalence classes:\n",
      "  Class 1: [1]\n",
      "  Class 2: [2, 3, 4, 5, 8, 9, 16, 17]\n",
      "\n",
      "Equivalent pairs (will be excluded from cross-hardware signal):\n",
      "  (2, 3)\n",
      "  (2, 4)\n",
      "  (2, 5)\n",
      "  (2, 8)\n",
      "  (2, 9)\n",
      "  (2, 16)\n",
      "  (2, 17)\n",
      "  (3, 4)\n",
      "  (3, 5)\n",
      "  (3, 8)\n",
      "  (3, 9)\n",
      "  (3, 16)\n",
      "  (3, 17)\n",
      "  (4, 5)\n",
      "  (4, 8)\n",
      "  (4, 9)\n",
      "  (4, 16)\n",
      "  (4, 17)\n",
      "  (5, 8)\n",
      "  (5, 9)\n",
      "  (5, 16)\n",
      "  (5, 17)\n",
      "  (8, 9)\n",
      "  (8, 16)\n",
      "  (8, 17)\n",
      "  (9, 16)\n",
      "  (9, 17)\n",
      "  (16, 17)\n",
      "\n",
      "✓ SANITY CHECK PASSED\n",
      "\n",
      "================================================================================\n",
      "WITHIN-HARDWARE BATCH SIZE EFFECTS (DECODE)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "REF_0\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  3.28e+01  2.88e+01  3.28e+01  3.29e+01  3.28e+01  3.28e+01  3.28e+01  9.10e+00\n",
      "bs=2    3.28e+01  0.00e+00  2.37e+01  7.62e-01  1.07e+00  1.28e+00  1.17e+00  7.84e-01  3.05e+01\n",
      "bs=3    2.88e+01  2.37e+01  0.00e+00  2.36e+01  2.36e+01  2.37e+01  2.36e+01  2.36e+01  2.70e+01\n",
      "bs=4    3.28e+01  7.62e-01  2.36e+01  0.00e+00  1.38e+00  9.21e-01  1.19e+00  7.92e-01  3.05e+01\n",
      "bs=5    3.29e+01  1.07e+00  2.36e+01  1.38e+00  0.00e+00  1.69e+00  1.58e+00  1.32e+00  3.05e+01\n",
      "bs=8    3.28e+01  1.28e+00  2.37e+01  9.21e-01  1.69e+00  0.00e+00  6.37e-01  1.36e+00  3.04e+01\n",
      "bs=9    3.28e+01  1.17e+00  2.36e+01  1.19e+00  1.58e+00  6.37e-01  0.00e+00  1.11e+00  3.04e+01\n",
      "bs=16   3.28e+01  7.84e-01  2.36e+01  7.92e-01  1.32e+00  1.36e+00  1.11e+00  0.00e+00  3.05e+01\n",
      "bs=17   9.10e+00  3.05e+01  2.70e+01  3.05e+01  3.05e+01  3.04e+01  3.04e+01  3.05e+01  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00       inf       inf       inf       inf       inf       inf       inf       inf\n",
      "bs=2         inf  0.00e+00       inf  1.91e-01  4.56e-01  2.12e-01  3.55e-01  1.31e-01       inf\n",
      "bs=3         inf       inf  0.00e+00       inf       inf       inf       inf       inf       inf\n",
      "bs=4         inf  1.91e-01       inf  0.00e+00  2.86e-01  2.04e-01  5.35e-01  2.34e-01       inf\n",
      "bs=5         inf  4.56e-01       inf  2.86e-01  0.00e+00  4.03e-01  6.93e-01  4.34e-01       inf\n",
      "bs=8         inf  2.12e-01       inf  2.04e-01  4.03e-01  0.00e+00  4.01e-01  1.65e-01       inf\n",
      "bs=9         inf  3.55e-01       inf  5.35e-01  6.93e-01  4.01e-01  0.00e+00  3.17e-01       inf\n",
      "bs=16        inf  1.31e-01       inf  2.34e-01  4.34e-01  1.65e-01  3.17e-01  0.00e+00       inf\n",
      "bs=17        inf       inf       inf       inf       inf       inf       inf       inf  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "REF_1\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  2.61e+01  2.71e+01  1.12e+01  8.42e-01  2.74e+01  3.00e+01  3.00e+01  2.59e+01\n",
      "bs=2    2.61e+01  0.00e+00  2.41e+01  2.52e+01  2.63e+01  2.69e+01  2.91e+01  2.91e+01  2.87e+01\n",
      "bs=3    2.71e+01  2.41e+01  0.00e+00  2.48e+01  2.72e+01  2.49e+01  3.24e+01  3.23e+01  2.59e+01\n",
      "bs=4    1.12e+01  2.52e+01  2.48e+01  0.00e+00  1.10e+01  2.74e+01  2.75e+01  2.75e+01  2.54e+01\n",
      "bs=5    8.42e-01  2.63e+01  2.72e+01  1.10e+01  0.00e+00  2.75e+01  3.01e+01  3.01e+01  2.60e+01\n",
      "bs=8    2.74e+01  2.69e+01  2.49e+01  2.74e+01  2.75e+01  0.00e+00  2.95e+01  2.94e+01  2.42e+01\n",
      "bs=9    3.00e+01  2.91e+01  3.24e+01  2.75e+01  3.01e+01  2.95e+01  0.00e+00  5.62e-01  3.10e+01\n",
      "bs=16   3.00e+01  2.91e+01  3.23e+01  2.75e+01  3.01e+01  2.94e+01  5.62e-01  0.00e+00  3.09e+01\n",
      "bs=17   2.59e+01  2.87e+01  2.59e+01  2.54e+01  2.60e+01  2.42e+01  3.10e+01  3.09e+01  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00       inf       inf       inf  5.51e-02       inf       inf       inf       inf\n",
      "bs=2         inf  0.00e+00       inf       inf       inf       inf       inf       inf       inf\n",
      "bs=3         inf       inf  0.00e+00       inf       inf       inf       inf       inf       inf\n",
      "bs=4         inf       inf       inf  0.00e+00       inf       inf       inf       inf       inf\n",
      "bs=5    8.60e-02       inf       inf       inf  0.00e+00       inf       inf       inf       inf\n",
      "bs=8         inf       inf       inf       inf       inf  0.00e+00       inf       inf       inf\n",
      "bs=9         inf       inf       inf       inf       inf       inf  0.00e+00  3.40e-01       inf\n",
      "bs=16        inf       inf       inf       inf       inf       inf  3.40e-01  0.00e+00       inf\n",
      "bs=17        inf       inf       inf       inf       inf       inf       inf       inf  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "REF_2\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  1.48e+00  2.62e+01  1.00e+00  2.62e+01  1.48e+00  2.61e+01  9.78e-01  1.16e+00\n",
      "bs=2    1.48e+00  0.00e+00  2.62e+01  1.15e+00  2.62e+01  2.81e-01  2.62e+01  1.14e+00  1.24e+00\n",
      "bs=3    2.62e+01  2.62e+01  0.00e+00  2.62e+01  3.08e-01  2.62e+01  3.08e-01  2.62e+01  2.63e+01\n",
      "bs=4    1.00e+00  1.15e+00  2.62e+01  0.00e+00  2.62e+01  1.12e+00  2.61e+01  3.63e-01  8.47e-01\n",
      "bs=5    2.62e+01  2.62e+01  3.08e-01  2.62e+01  0.00e+00  2.62e+01  3.36e-01  2.62e+01  2.63e+01\n",
      "bs=8    1.48e+00  2.81e-01  2.62e+01  1.12e+00  2.62e+01  0.00e+00  2.61e+01  1.14e+00  1.23e+00\n",
      "bs=9    2.61e+01  2.62e+01  3.08e-01  2.61e+01  3.36e-01  2.61e+01  0.00e+00  2.61e+01  2.62e+01\n",
      "bs=16   9.78e-01  1.14e+00  2.62e+01  3.63e-01  2.62e+01  1.14e+00  2.61e+01  0.00e+00  8.97e-01\n",
      "bs=17   1.16e+00  1.24e+00  2.63e+01  8.47e-01  2.63e+01  1.23e+00  2.62e+01  8.97e-01  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  1.21e-01       inf  1.09e-01       inf  1.68e-01       inf  1.14e-01  4.60e-01\n",
      "bs=2    1.21e-01  0.00e+00       inf  1.32e-01       inf  1.79e-01       inf  7.90e-02  4.29e-01\n",
      "bs=3         inf       inf  0.00e+00       inf  1.08e-01       inf  1.72e-01       inf       inf\n",
      "bs=4    1.09e-01  1.32e-01       inf  0.00e+00       inf  7.90e-02       inf  7.40e-02  4.72e-01\n",
      "bs=5         inf       inf  1.08e-01       inf  0.00e+00       inf  1.71e-01       inf       inf\n",
      "bs=8    1.68e-01  1.79e-01       inf  7.90e-02       inf  0.00e+00       inf  1.52e-01  5.34e-01\n",
      "bs=9         inf       inf  1.72e-01       inf  1.71e-01       inf  0.00e+00       inf       inf\n",
      "bs=16   1.14e-01  7.90e-02       inf  7.40e-02       inf  1.52e-01       inf  0.00e+00  4.20e-01\n",
      "bs=17   4.60e-01  4.29e-01       inf  4.72e-01       inf  5.34e-01       inf  4.20e-01  0.00e+00\n",
      "\n",
      "================================================================================\n",
      "AGGREGATE (average across references):\n",
      "================================================================================\n",
      "\n",
      "Key Vectors (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00  2.02e+01  2.74e+01  1.50e+01  2.00e+01  2.06e+01  2.97e+01  2.13e+01  1.20e+01\n",
      "bs=2    2.02e+01  0.00e+00  2.47e+01  9.04e+00  1.79e+01  9.48e+00  1.88e+01  1.03e+01  2.01e+01\n",
      "bs=3    2.74e+01  2.47e+01  0.00e+00  2.49e+01  1.71e+01  2.49e+01  1.88e+01  2.74e+01  2.64e+01\n",
      "bs=4    1.50e+01  9.04e+00  2.49e+01  0.00e+00  1.29e+01  9.83e+00  1.83e+01  9.55e+00  1.89e+01\n",
      "bs=5    2.00e+01  1.79e+01  1.71e+01  1.29e+01  0.00e+00  1.85e+01  1.07e+01  1.92e+01  2.76e+01\n",
      "bs=8    2.06e+01  9.48e+00  2.49e+01  9.83e+00  1.85e+01  0.00e+00  1.87e+01  1.06e+01  1.86e+01\n",
      "bs=9    2.97e+01  1.88e+01  1.88e+01  1.83e+01  1.07e+01  1.87e+01  0.00e+00  9.27e+00  2.92e+01\n",
      "bs=16   2.13e+01  1.03e+01  2.74e+01  9.55e+00  1.92e+01  1.06e+01  9.27e+00  0.00e+00  2.07e+01\n",
      "bs=17   1.20e+01  2.01e+01  2.64e+01  1.89e+01  2.76e+01  1.86e+01  2.92e+01  2.07e+01  0.00e+00\n",
      "\n",
      "Logprobs (mean L2 distance):\n",
      "       bs=  1 bs=  2 bs=  3 bs=  4 bs=  5 bs=  8 bs=  9 bs= 16 bs= 17 \n",
      "bs=1    0.00e+00       inf       inf       inf       inf       inf       inf       inf       inf\n",
      "bs=2         inf  0.00e+00       inf       inf       inf       inf       inf       inf       inf\n",
      "bs=3         inf       inf  0.00e+00       inf       inf       inf       inf       inf       inf\n",
      "bs=4         inf       inf       inf  0.00e+00       inf       inf       inf       inf       inf\n",
      "bs=5         inf       inf       inf       inf  0.00e+00       inf       inf       inf       inf\n",
      "bs=8         inf       inf       inf       inf       inf  0.00e+00       inf       inf       inf\n",
      "bs=9         inf       inf       inf       inf       inf       inf  0.00e+00       inf       inf\n",
      "bs=16        inf       inf       inf       inf       inf       inf       inf  0.00e+00       inf\n",
      "bs=17        inf       inf       inf       inf       inf       inf       inf       inf  0.00e+00\n",
      "\n",
      "Off-diagonal stats:\n",
      "  Key vectors - Mean: 1.86e+01, Range: [9.04e+00, 2.97e+01]\n",
      "  Logprobs - Mean: 0.00e+00, Range: [inf, inf]\n",
      "\n",
      "Kernel equivalence classes:\n",
      "  Class 1: [1]\n",
      "  Class 2: [2]\n",
      "  Class 3: [3]\n",
      "  Class 4: [4]\n",
      "  Class 5: [5]\n",
      "  Class 6: [8]\n",
      "  Class 7: [9]\n",
      "  Class 8: [16]\n",
      "  Class 9: [17]\n",
      "\n",
      "✗ SANITY CHECK FAILED (No variation)\n",
      "\n",
      "✓ Saved to: /workspace/experiments/decode_20251126_163654.json\n",
      "\n",
      "Next step: Copy to verifier machine, set TEACHER_FORCING=True\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Cross-Hardware Prefill vs Decode Detectability Experiment (Transformers)\n",
    "\n",
    "Tests whether batch size claims can be verified across different GPU architectures\n",
    "using floating-point forensics (key vectors and logprobs).\n",
    "\n",
    "UPDATED: Uses chat-formatted prompts for more realistic/higher-entropy responses.\n",
    "\n",
    "Workflow:\n",
    "1. Run on Machine A (e.g., A100) with TEACHER_FORCING = False\n",
    "   → Generates tokens, extracts prefill + decode signals, saves to JSON\n",
    "2. Copy JSON to Machine B (e.g., H100)\n",
    "3. Run on Machine B with TEACHER_FORCING = True\n",
    "   → Teacher-forces A's tokens, extracts signals, compares\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/workspace/huggingface_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/huggingface_cache'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import socket\n",
    "import platform\n",
    "import sys\n",
    "import glob\n",
    "import PyPDF2\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "TEACHER_FORCING = False\n",
    "REFERENCE_FILE = \"/workspace/experiments/decode_reference.json\"\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "CACHE_DIR = '/workspace/huggingface_cache'\n",
    "ATTN_IMPLEMENTATION = \"sdpa\"  # Options: \"eager\", \"sdpa\", \"flash_attention_2\"\n",
    "\n",
    "BATCH_SIZES = [1, 2, 3, 4, 5, 8, 9, 16, 17]\n",
    "LAYER_INDICES = [28]  # Last layer only\n",
    "MAX_NEW_TOKENS = 150\n",
    "TOKENS_PER_SLICE = 3000  \n",
    "NUM_REFERENCES = 3\n",
    "\n",
    "# Threshold for considering two batch sizes \"equivalent\" (same kernel)\n",
    "EQUIVALENCE_THRESHOLD = 1e-9\n",
    "\n",
    "# Will be initialized from PDF in main()\n",
    "REFERENCE_SEQUENCES = None  # Now contains token IDs, not text\n",
    "DUMMY_SETS = None           # Now contains token IDs, not text\n",
    "\n",
    "# ============================================================================\n",
    "# CHAT TEMPLATE CONFIGURATION (Qwen recommended)\n",
    "# ============================================================================\n",
    "\n",
    "SYSTEM_PROMPT = \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Here is an excerpt from a document:\n",
    "\n",
    "\"{snippet}\"\n",
    "\n",
    "Based on this excerpt, what type of document do you think this is from, and what is its likely subject matter? Explain your reasoning.\"\"\"\n",
    "\n",
    "\n",
    "def create_chat_messages(snippet_text):\n",
    "    \"\"\"Create chat messages list for the tokenizer.\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_TEMPLATE.format(snippet=snippet_text.strip())}\n",
    "    ]\n",
    "\n",
    "\n",
    "def tokenize_chat_prompt(tokenizer, snippet_text):\n",
    "    \"\"\"\n",
    "    Tokenize a chat prompt using the tokenizer's apply_chat_template.\n",
    "    Returns token IDs ready for model input.\n",
    "    \"\"\"\n",
    "    messages = create_chat_messages(snippet_text)\n",
    "    token_ids = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    return token_ids\n",
    "\n",
    "# ============================================================================\n",
    "# LOGGING SETUP\n",
    "# ============================================================================\n",
    "\n",
    "LOG_FILE = None\n",
    "\n",
    "def setup_logging(output_dir='/workspace/experiments'):\n",
    "    \"\"\"Setup logging to file.\"\"\"\n",
    "    global LOG_FILE\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    mode = \"verify\" if TEACHER_FORCING else \"generate\"\n",
    "    log_path = os.path.join(output_dir, f\"experiment_{mode}_{timestamp}.txt\")\n",
    "    LOG_FILE = open(log_path, 'w')\n",
    "    return log_path\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    \"\"\"Print to both console and log file.\"\"\"\n",
    "    print(*args, **kwargs)\n",
    "    if LOG_FILE:\n",
    "        log_kwargs = {k: v for k, v in kwargs.items() if k != 'file'}\n",
    "        print(*args, **log_kwargs, file=LOG_FILE)\n",
    "        LOG_FILE.flush()\n",
    "\n",
    "def close_logging():\n",
    "    \"\"\"Close log file.\"\"\"\n",
    "    global LOG_FILE\n",
    "    if LOG_FILE:\n",
    "        LOG_FILE.close()\n",
    "        LOG_FILE = None\n",
    "\n",
    "# ============================================================================\n",
    "# PDF LOADING - UPDATED TO RETURN TOKEN IDS WITH CHAT TEMPLATE\n",
    "# ============================================================================\n",
    "\n",
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text content from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \" \"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def create_sequences_from_pdf(tokenizer, num_references=NUM_REFERENCES):\n",
    "    \"\"\"\n",
    "    Load all PDFs, create chat-formatted prompts, and return token IDs.\n",
    "    All assembly done at token level - guaranteed identical lengths.\n",
    "    \"\"\"\n",
    "    pdf_files = glob.glob(\"/workspace/*.pdf\")\n",
    "    if not pdf_files:\n",
    "        pdf_files = glob.glob(\"*.pdf\")\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(\"No PDF files found\")\n",
    "\n",
    "    log_print(f\"Found {len(pdf_files)} PDF(s)\")\n",
    "\n",
    "    all_text = \"\"\n",
    "    for pdf_path in pdf_files:\n",
    "        log_print(f\"  Loading: {pdf_path}\")\n",
    "        text = load_pdf_text(pdf_path)\n",
    "        all_text += text + \" \"\n",
    "\n",
    "    # Tokenize PDF content\n",
    "    content_tokens = tokenizer.encode(all_text, add_special_tokens=False)\n",
    "    log_print(f\"Total source tokens: {len(content_tokens)}\")\n",
    "\n",
    "    max_batch_size = max(BATCH_SIZES)\n",
    "    slices_needed = num_references * max_batch_size\n",
    "\n",
    "    if len(content_tokens) < slices_needed * TOKENS_PER_SLICE:\n",
    "        raise ValueError(f\"Need {slices_needed * TOKENS_PER_SLICE} tokens but only have {len(content_tokens)}\")\n",
    "\n",
    "    # Tokenize template parts (prefix before snippet, suffix after)\n",
    "    prefix = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "Here is an excerpt from a document:\n",
    "\n",
    "\\\"\"\"\"\n",
    "    \n",
    "    suffix = f\"\"\"\"\n",
    "\n",
    "Based on this excerpt, what type of document do you think this is from, and what is its likely subject matter? Explain your reasoning.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    prefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\n",
    "    suffix_tokens = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "    \n",
    "    total_len = len(prefix_tokens) + TOKENS_PER_SLICE + len(suffix_tokens)\n",
    "    log_print(f\"Prompt structure: {len(prefix_tokens)} prefix + {TOKENS_PER_SLICE} snippet + {len(suffix_tokens)} suffix = {total_len} tokens\")\n",
    "\n",
    "    # Assemble prompts at token level\n",
    "    all_prompts = []\n",
    "    for i in range(slices_needed):\n",
    "        start = i * TOKENS_PER_SLICE\n",
    "        end = start + TOKENS_PER_SLICE\n",
    "        snippet_tokens = content_tokens[start:end]\n",
    "        prompt = prefix_tokens + snippet_tokens + suffix_tokens\n",
    "        all_prompts.append(prompt)\n",
    "    \n",
    "    # Verify\n",
    "    lengths = set(len(p) for p in all_prompts)\n",
    "    assert len(lengths) == 1, f\"Length mismatch: {lengths}\"\n",
    "    log_print(f\"All {slices_needed} prompts: {total_len} tokens each\")\n",
    "    \n",
    "    # Show sample ending\n",
    "    log_print(f\"\\nSample prompt ending:\")\n",
    "    log_print(repr(tokenizer.decode(all_prompts[0][-40:])))\n",
    "\n",
    "    reference_sequences = {}\n",
    "    dummy_sets = {}\n",
    "\n",
    "    for ref_idx in range(num_references):\n",
    "        ref_name = f\"ref_{ref_idx}\"\n",
    "        base_idx = ref_idx * max_batch_size\n",
    "        reference_sequences[ref_name] = all_prompts[base_idx]\n",
    "        dummy_sets[ref_name] = all_prompts[base_idx + 1 : base_idx + max_batch_size]\n",
    "\n",
    "    return reference_sequences, dummy_sets\n",
    "\n",
    "# ============================================================================\n",
    "# SYSTEM INFO\n",
    "# ============================================================================\n",
    "\n",
    "def collect_system_info():\n",
    "    \"\"\"Collect comprehensive environment information.\"\"\"\n",
    "    import transformers\n",
    "    \n",
    "    info = {\n",
    "        \"hostname\": socket.gethostname(),\n",
    "        \"platform\": platform.platform(),\n",
    "        \"python_version\": sys.version.split()[0],\n",
    "        \"torch_version\": torch.__version__,\n",
    "        \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
    "        \"cudnn_version\": str(torch.backends.cudnn.version()) if torch.cuda.is_available() else \"N/A\",\n",
    "        \"transformers_version\": transformers.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "        \"attn_implementation\": ATTN_IMPLEMENTATION,\n",
    "        \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\",\n",
    "        \"gpu_count\": torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        import flash_attn\n",
    "        info[\"flash_attn_version\"] = flash_attn.__version__\n",
    "    except ImportError:\n",
    "        info[\"flash_attn_version\"] = \"N/A\"\n",
    "        \n",
    "    return info\n",
    "\n",
    "def validate_environment_match(reference_env, verifier_env):\n",
    "    \"\"\"\n",
    "    Validate that software environments match between reference and verifier.\n",
    "    \"\"\"\n",
    "    log_print(\"\\n\" + \"=\"*80)\n",
    "    log_print(\"ENVIRONMENT VALIDATION\")\n",
    "    log_print(\"=\"*80)\n",
    "    \n",
    "    container_fields = ['python_version', 'cuda_version', 'cudnn_version']\n",
    "    pip_fields = ['torch_version', 'transformers_version', 'numpy_version', 'flash_attn_version']\n",
    "    config_fields = ['attn_implementation']\n",
    "    expected_different = ['gpu_name', 'hostname']\n",
    "    \n",
    "    container_mismatches = []\n",
    "    pip_mismatches = []\n",
    "    config_mismatches = []\n",
    "    \n",
    "    log_print(\"\\nScript configuration:\")\n",
    "    for field in config_fields:\n",
    "        ref_val = reference_env.get(field, 'N/A')\n",
    "        ver_val = verifier_env.get(field, 'N/A')\n",
    "        if ref_val == ver_val:\n",
    "            log_print(f\"  ✓ {field}: {ref_val}\")\n",
    "        else:\n",
    "            log_print(f\"  ✗ {field}: reference={ref_val}, verifier={ver_val}\")\n",
    "            config_mismatches.append((field, ref_val, ver_val))\n",
    "\n",
    "    log_print(\"\\nContainer-level dependencies:\")\n",
    "    for field in container_fields:\n",
    "        ref_val = reference_env.get(field, 'N/A')\n",
    "        ver_val = verifier_env.get(field, 'N/A')\n",
    "        if ref_val == ver_val:\n",
    "            log_print(f\"  ✓ {field}: {ref_val}\")\n",
    "        else:\n",
    "            log_print(f\"  ✗ {field}: reference={ref_val}, verifier={ver_val}\")\n",
    "            container_mismatches.append((field, ref_val, ver_val))\n",
    "\n",
    "    log_print(\"\\nPip-installable packages:\")\n",
    "    for field in pip_fields:\n",
    "        ref_val = reference_env.get(field, 'N/A')\n",
    "        ver_val = verifier_env.get(field, 'N/A')\n",
    "        \n",
    "        if field == 'flash_attn_version':\n",
    "            ref_attn = reference_env.get('attn_implementation', '')\n",
    "            ver_attn = verifier_env.get('attn_implementation', '')\n",
    "            if ref_attn != 'flash_attention_2' and ver_attn != 'flash_attention_2':\n",
    "                log_print(f\"  - {field}: not using flash_attention_2 (skip)\")\n",
    "                continue\n",
    "            if ref_val == 'N/A' or ver_val == 'N/A':\n",
    "                log_print(f\"  ✗ {field}: reference={ref_val}, verifier={ver_val}\")\n",
    "                pip_mismatches.append((field, ref_val, ver_val))\n",
    "                continue\n",
    "        \n",
    "        if ref_val == 'N/A' and ver_val == 'N/A':\n",
    "            log_print(f\"  - {field}: not installed (OK)\")\n",
    "            continue\n",
    "            \n",
    "        if ref_val == ver_val:\n",
    "            log_print(f\"  ✓ {field}: {ref_val}\")\n",
    "        else:\n",
    "            log_print(f\"  ✗ {field}: reference={ref_val}, verifier={ver_val}\")\n",
    "            pip_mismatches.append((field, ref_val, ver_val))\n",
    "\n",
    "    log_print(\"\\nExpected differences (hardware):\")\n",
    "    for field in expected_different:\n",
    "        ref_val = reference_env.get(field, 'N/A')\n",
    "        ver_val = verifier_env.get(field, 'N/A')\n",
    "        if ref_val != ver_val:\n",
    "            log_print(f\"  ✓ {field}: reference={ref_val}, verifier={ver_val}\")\n",
    "        else:\n",
    "            log_print(f\"  ⚠ {field}: SAME ({ref_val}) - are you on different hardware?\")\n",
    "\n",
    "    if not container_mismatches and not pip_mismatches and not config_mismatches:\n",
    "        log_print(\"\\n\" + \"-\"*60)\n",
    "        log_print(\"✓ ENVIRONMENT VALIDATION PASSED\")\n",
    "        return {'valid': True, 'mismatches': []}\n",
    "    \n",
    "    log_print(\"\\n\" + \"=\"*80)\n",
    "    log_print(\"✗ ENVIRONMENT MISMATCH - FIX REQUIRED\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ============================================================================\n",
    "# SIGNAL EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "def extract_signals_from_output(outputs, layer_indices, position=-1):\n",
    "    \"\"\"\n",
    "    Extract key vectors and logprobs from element 0 at specified position.\n",
    "    \"\"\"\n",
    "    signals = {\n",
    "        'key_vectors': {},\n",
    "        'logprobs': {}\n",
    "    }\n",
    "\n",
    "    for layer_idx in layer_indices:\n",
    "        layer_keys = outputs.past_key_values[layer_idx - 1][0]\n",
    "        token_keys = layer_keys[0, :, position, :]\n",
    "        key_dim = token_keys.shape[0] * token_keys.shape[1]\n",
    "        key_vector = token_keys.reshape(key_dim).cpu().clone()\n",
    "        signals['key_vectors'][f'layer_{layer_idx}'] = key_vector.float().numpy().tolist()\n",
    "\n",
    "    logits = outputs.logits[0, position, :]\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    top_k = torch.topk(log_probs, k=20)\n",
    "\n",
    "    signals['logprobs'] = {\n",
    "        'token_ids': top_k.indices.cpu().tolist(),\n",
    "        'log_probs': top_k.values.cpu().tolist()\n",
    "    }\n",
    "\n",
    "    return signals\n",
    "\n",
    "def extract_prefill_signals(outputs, layer_indices, positions=[-3, -2, -1]):\n",
    "    \"\"\"Extract signals from multiple positions during prefill.\"\"\"\n",
    "    prefill_signals = {}\n",
    "    for pos in positions:\n",
    "        pos_label = f\"pos_{pos}\"\n",
    "        prefill_signals[pos_label] = extract_signals_from_output(outputs, layer_indices, position=pos)\n",
    "    return prefill_signals\n",
    "\n",
    "def extract_signals_for_token_ids(outputs, layer_indices, token_ids, position=-1):\n",
    "    \"\"\"Extract signals for SPECIFIC token IDs (used in verification).\"\"\"\n",
    "    signals = {\n",
    "        'key_vectors': {},\n",
    "        'logprobs': {}\n",
    "    }\n",
    "\n",
    "    for layer_idx in layer_indices:\n",
    "        layer_keys = outputs.past_key_values[layer_idx - 1][0]\n",
    "        token_keys = layer_keys[0, :, position, :]\n",
    "        key_dim = token_keys.shape[0] * token_keys.shape[1]\n",
    "        key_vector = token_keys.reshape(key_dim).cpu().clone()\n",
    "        signals['key_vectors'][f'layer_{layer_idx}'] = key_vector.float().numpy().tolist()\n",
    "\n",
    "    logits = outputs.logits[0, position, :]\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_ids_tensor = torch.tensor(token_ids, device=logits.device)\n",
    "    selected_logprobs = log_probs[token_ids_tensor]\n",
    "\n",
    "    signals['logprobs'] = {\n",
    "        'token_ids': token_ids,\n",
    "        'log_probs': selected_logprobs.cpu().tolist()\n",
    "    }\n",
    "\n",
    "    return signals\n",
    "\n",
    "def extract_prefill_signals_for_token_ids(outputs, layer_indices, ref_prefill_signals, positions=[-3, -2, -1]):\n",
    "    \"\"\"Extract prefill signals using reference token IDs.\"\"\"\n",
    "    prefill_signals = {}\n",
    "    for pos in positions:\n",
    "        pos_label = f\"pos_{pos}\"\n",
    "        if pos_label in ref_prefill_signals:\n",
    "            ref_token_ids = ref_prefill_signals[pos_label]['logprobs']['token_ids']\n",
    "            prefill_signals[pos_label] = extract_signals_for_token_ids(\n",
    "                outputs, layer_indices, ref_token_ids, position=pos\n",
    "            )\n",
    "    return prefill_signals\n",
    "\n",
    "# ============================================================================\n",
    "# DECODE GENERATION (TEACHER_FORCING = False) - UPDATED FOR TOKEN IDS\n",
    "# ============================================================================\n",
    "\n",
    "def run_decode_with_extraction(model, tokenizer, ref_token_ids, ref_name, batch_size, \n",
    "                               layer_indices):\n",
    "    \"\"\"\n",
    "    Run decode generation and extract signals from last 3 generation steps.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    ref_dummies = DUMMY_SETS[ref_name]\n",
    "    if batch_size == 1:\n",
    "        batch_token_ids = [ref_token_ids]\n",
    "    else:\n",
    "        batch_token_ids = [ref_token_ids] + ref_dummies[:batch_size-1]\n",
    "    \n",
    "    input_ids = torch.tensor(batch_token_ids, dtype=torch.long, device='cuda')\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "    \n",
    "    prompt_length = input_ids.shape[1]\n",
    "    log_print(f\"      Prompt: {prompt_length} tokens\", end=\"\")\n",
    "    \n",
    "    all_batch_generated_ids = [[] for _ in range(batch_size)]\n",
    "    generation_signals = []\n",
    "    \n",
    "    # FIRST STEP: Prefill\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, use_cache=True)\n",
    "        \n",
    "    past_kv = outputs.past_key_values\n",
    "    prefill_signals = extract_prefill_signals(outputs, layer_indices, positions=[-3, -2, -1])\n",
    "    \n",
    "    next_tokens = outputs.logits[:, -1, :].argmax(dim=-1)\n",
    "    for batch_idx in range(batch_size):\n",
    "        all_batch_generated_ids[batch_idx].append(next_tokens[batch_idx].item())\n",
    "        \n",
    "    signals = extract_signals_from_output(outputs, layer_indices, position=-1)\n",
    "    absolute_position_index = inputs['input_ids'].shape[1] - 1\n",
    "    \n",
    "    generation_signals.append({\n",
    "        'step': 0,\n",
    "        'absolute_position': absolute_position_index,\n",
    "        'signals': signals\n",
    "    })\n",
    "    \n",
    "    attention_mask = torch.cat([\n",
    "        inputs['attention_mask'], \n",
    "        torch.ones((inputs['attention_mask'].shape[0], 1), device='cuda')\n",
    "    ], dim=1)\n",
    "    \n",
    "    # SUBSEQUENT STEPS\n",
    "    for step in range(1, MAX_NEW_TOKENS):\n",
    "        new_inputs = {\n",
    "            'input_ids': next_tokens.unsqueeze(1),\n",
    "            'attention_mask': attention_mask,\n",
    "            'past_key_values': past_kv,\n",
    "            'use_cache': True\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**new_inputs)\n",
    "        \n",
    "        past_kv = outputs.past_key_values\n",
    "        \n",
    "        next_tokens = outputs.logits[:, -1, :].argmax(dim=-1)\n",
    "        for batch_idx in range(batch_size):\n",
    "            all_batch_generated_ids[batch_idx].append(next_tokens[batch_idx].item())\n",
    "            \n",
    "        signals = extract_signals_from_output(outputs, layer_indices, position=-1)\n",
    "        current_cache_length = past_kv[0][0].shape[2]\n",
    "        absolute_position_index = current_cache_length - 1\n",
    "        \n",
    "        generation_signals.append({\n",
    "            'step': step,\n",
    "            'absolute_position': absolute_position_index,\n",
    "            'signals': signals\n",
    "        })\n",
    "        \n",
    "        attention_mask = torch.cat([\n",
    "            attention_mask, \n",
    "            torch.ones((attention_mask.shape[0], 1), device='cuda')\n",
    "        ], dim=1)\n",
    "        \n",
    "        if all_batch_generated_ids[0][-1] == tokenizer.eos_token_id:\n",
    "            break\n",
    "            \n",
    "    # Extract last 3 decode signals\n",
    "    num_generated = len(generation_signals)\n",
    "    if num_generated >= 3:\n",
    "        last_3_signals = {\n",
    "            'pos_-3': generation_signals[-3],\n",
    "            'pos_-2': generation_signals[-2],\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    elif num_generated == 2:\n",
    "        last_3_signals = {\n",
    "            'pos_-2': generation_signals[-2],\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    elif num_generated == 1:\n",
    "        last_3_signals = {\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    else:\n",
    "        last_3_signals = {}\n",
    "        \n",
    "    del outputs, inputs, past_kv\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    final_length = prompt_length + num_generated\n",
    "    log_print(f\" → Final: {final_length} tokens ({num_generated} generated)\")\n",
    "    \n",
    "    return {\n",
    "        'generated_ids': all_batch_generated_ids[0],\n",
    "        'all_batch_generated_ids': all_batch_generated_ids,\n",
    "        'prompt_token_ids': batch_token_ids,\n",
    "        'prompt_length': prompt_length,\n",
    "        'prefill_signals': prefill_signals,\n",
    "        'decode_signals': last_3_signals,\n",
    "        'num_generated': num_generated\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TEACHER-FORCED DECODE (TEACHER_FORCING = True) - UPDATED FOR TOKEN IDS\n",
    "# ============================================================================\n",
    "\n",
    "def run_teacher_forced_decode(model, tokenizer, ref_name, reference_data, \n",
    "                              verify_batch_size, layer_indices, is_diagonal):\n",
    "    \"\"\"\n",
    "    Teacher-forced decode: feed reference tokens, extract signals.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    ref_prompt_ids = reference_data['prompt_token_ids'][0]\n",
    "    ref_generated_ids = reference_data['generated_ids']\n",
    "    ref_batch_size = len(reference_data['prompt_token_ids'])\n",
    "    \n",
    "    log_print(f\"      Prompt: {len(ref_prompt_ids)}, Gen: {len(ref_generated_ids)}\", end=\"\")\n",
    "    \n",
    "    if is_diagonal:\n",
    "        log_print(f\", exact neighbors (bs={ref_batch_size})\", end=\"\")\n",
    "        batch_prompt_ids = reference_data['prompt_token_ids']\n",
    "        batch_generated_ids = reference_data['all_batch_generated_ids']\n",
    "        actual_batch_size = ref_batch_size\n",
    "    else:\n",
    "        log_print(f\", arb neighbors (bs={verify_batch_size})\", end=\"\")\n",
    "        batch_prompt_ids = [ref_prompt_ids]\n",
    "        batch_generated_ids = [ref_generated_ids]\n",
    "        \n",
    "        ref_dummies = DUMMY_SETS[ref_name]\n",
    "        for i in range(verify_batch_size - 1):\n",
    "            batch_prompt_ids.append(ref_dummies[i])\n",
    "            batch_generated_ids.append([])\n",
    "        \n",
    "        actual_batch_size = verify_batch_size\n",
    "        \n",
    "    input_ids = torch.tensor(batch_prompt_ids, dtype=torch.long, device='cuda')\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "    generation_signals = []\n",
    "    num_steps = len(ref_generated_ids)\n",
    "    \n",
    "    # FIRST STEP: Prefill\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, use_cache=True)\n",
    "        \n",
    "    past_kv = outputs.past_key_values\n",
    "    ref_prefill_signals = reference_data['prefill_signals']\n",
    "    prefill_signals = extract_prefill_signals_for_token_ids(\n",
    "        outputs, layer_indices, ref_prefill_signals, positions=[-3, -2, -1]\n",
    "    )\n",
    "    \n",
    "    ref_decode_signals = reference_data['decode_signals']\n",
    "    ref_step_data = list(ref_decode_signals.values())[0] if ref_decode_signals else None\n",
    "    if ref_step_data:\n",
    "        ref_token_ids = ref_step_data['signals']['logprobs']['token_ids']\n",
    "        signals = extract_signals_for_token_ids(outputs, layer_indices, ref_token_ids, position=-1)\n",
    "    else:\n",
    "        signals = extract_signals_from_output(outputs, layer_indices, position=-1)\n",
    "        \n",
    "    absolute_position_index = inputs['input_ids'].shape[1] - 1\n",
    "    generation_signals.append({\n",
    "        'step': 0,\n",
    "        'absolute_position': absolute_position_index,\n",
    "        'signals': signals\n",
    "    })\n",
    "    \n",
    "    # Prepare next tokens\n",
    "    if is_diagonal:\n",
    "        next_tokens = torch.tensor(\n",
    "            [batch_generated_ids[i][0] for i in range(actual_batch_size)],\n",
    "            dtype=torch.long, device='cuda'\n",
    "        )\n",
    "    else:\n",
    "        next_tokens_list = [ref_generated_ids[0]]\n",
    "        argmax_tokens = outputs.logits[1:, -1, :].argmax(dim=-1)\n",
    "        for i in range(actual_batch_size - 1):\n",
    "            next_tokens_list.append(argmax_tokens[i].item())\n",
    "            batch_generated_ids[i + 1].append(argmax_tokens[i].item())\n",
    "        next_tokens = torch.tensor(next_tokens_list, dtype=torch.long, device='cuda')\n",
    "        \n",
    "    attention_mask = torch.cat([\n",
    "        inputs['attention_mask'], \n",
    "        torch.ones((actual_batch_size, 1), device='cuda')\n",
    "    ], dim=1)\n",
    "    \n",
    "    # SUBSEQUENT STEPS\n",
    "    for step in range(1, num_steps):\n",
    "        new_inputs = {\n",
    "            'input_ids': next_tokens.unsqueeze(1),\n",
    "            'attention_mask': attention_mask,\n",
    "            'past_key_values': past_kv,\n",
    "            'use_cache': True\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**new_inputs)\n",
    "        \n",
    "        past_kv = outputs.past_key_values\n",
    "        \n",
    "        ref_signals_list = list(ref_decode_signals.values())\n",
    "        if step < len(ref_signals_list):\n",
    "            ref_token_ids = ref_signals_list[step]['signals']['logprobs']['token_ids']\n",
    "            signals = extract_signals_for_token_ids(outputs, layer_indices, ref_token_ids, position=-1)\n",
    "        else:\n",
    "            signals = extract_signals_from_output(outputs, layer_indices, position=-1)\n",
    "            \n",
    "        current_cache_length = past_kv[0][0].shape[2]\n",
    "        absolute_position_index = current_cache_length - 1\n",
    "        \n",
    "        generation_signals.append({\n",
    "            'step': step,\n",
    "            'absolute_position': absolute_position_index,\n",
    "            'signals': signals\n",
    "        })\n",
    "        \n",
    "        if step < num_steps - 1:\n",
    "            if is_diagonal:\n",
    "                next_tokens = torch.tensor(\n",
    "                    [batch_generated_ids[i][step] for i in range(actual_batch_size)],\n",
    "                    dtype=torch.long, device='cuda'\n",
    "                )\n",
    "            else:\n",
    "                next_tokens_list = [ref_generated_ids[step]]\n",
    "                argmax_tokens = outputs.logits[1:, -1, :].argmax(dim=-1)\n",
    "                for i in range(actual_batch_size - 1):\n",
    "                    next_tokens_list.append(argmax_tokens[i].item())\n",
    "                    batch_generated_ids[i + 1].append(argmax_tokens[i].item())\n",
    "                next_tokens = torch.tensor(next_tokens_list, dtype=torch.long, device='cuda')\n",
    "        \n",
    "        attention_mask = torch.cat([\n",
    "            attention_mask, \n",
    "            torch.ones((actual_batch_size, 1), device='cuda')\n",
    "        ], dim=1)\n",
    "        \n",
    "    # Extract last 3\n",
    "    num_generated = len(generation_signals)\n",
    "    if num_generated >= 3:\n",
    "        last_3_signals = {\n",
    "            'pos_-3': generation_signals[-3],\n",
    "            'pos_-2': generation_signals[-2],\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    elif num_generated == 2:\n",
    "        last_3_signals = {\n",
    "            'pos_-2': generation_signals[-2],\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    elif num_generated == 1:\n",
    "        last_3_signals = {\n",
    "            'pos_-1': generation_signals[-1]\n",
    "        }\n",
    "    else:\n",
    "        last_3_signals = {}\n",
    "        \n",
    "    del outputs, inputs, past_kv\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    log_print(f\" → {num_generated} steps\")\n",
    "    \n",
    "    return {\n",
    "        'prefill_signals': prefill_signals,\n",
    "        'decode_signals': last_3_signals,\n",
    "        'num_generated': num_generated\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def check_token_consistency(decode_measurements, tokenizer):\n",
    "    \"\"\"Verify element 0 generates identical tokens across all batch sizes.\"\"\"\n",
    "    log_print(\"\\n\" + \"=\"*80)\n",
    "    log_print(\"TOKEN GENERATION CONSISTENCY CHECK\")\n",
    "    log_print(\"=\"*80)\n",
    "    \n",
    "    tokens_by_bs = {}\n",
    "    for bs, data in decode_measurements.items():\n",
    "        tokens_by_bs[bs] = data['generated_ids']\n",
    "        \n",
    "    bs_list = sorted(tokens_by_bs.keys())\n",
    "    reference_tokens = tokens_by_bs[bs_list[0]]\n",
    "    \n",
    "    all_same = True\n",
    "    log_print(\"\\nGenerated tokens by batch size:\")\n",
    "    for bs in bs_list:\n",
    "        tokens = tokens_by_bs[bs]\n",
    "        match_str = \"✓\" if tokens == reference_tokens else \"✗ DIFFERENT\"\n",
    "        decoded_text = tokenizer.decode(tokens)\n",
    "        log_print(f\"  bs={bs}:\")\n",
    "        log_print(f\"    IDs:  {tokens}\")\n",
    "        log_print(f\"    Text: {repr(decoded_text)}\")\n",
    "        log_print(f\"    {match_str}\")\n",
    "        if tokens != reference_tokens:\n",
    "            all_same = False\n",
    "            \n",
    "    if all_same:\n",
    "        log_print(\"\\n✓ Element 0 generates IDENTICAL tokens across all batch sizes\")\n",
    "    else:\n",
    "        log_print(\"\\n⚠ Element 0 generates DIFFERENT tokens across batch sizes\")\n",
    "        \n",
    "    return all_same\n",
    "\n",
    "def compute_l2_distance(vec1, vec2):\n",
    "    \"\"\"Compute L2 distance between two vectors.\"\"\"\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return float(np.linalg.norm(v1 - v2))\n",
    "\n",
    "def compute_logprob_distance(logprobs1, logprobs2):\n",
    "    \"\"\"\n",
    "    Compute L2 distance between logprob distributions.\n",
    "    Uses top 5 token IDs from first signal as canonical (stored top 20 as buffer).\n",
    "    \"\"\"\n",
    "    canonical_ids = logprobs1['token_ids'][:5]\n",
    "    vec1 = logprobs1['log_probs'][:5]\n",
    "    \n",
    "    map2 = dict(zip(logprobs2['token_ids'], logprobs2['log_probs']))\n",
    "    \n",
    "    vec2 = []\n",
    "    for tid in canonical_ids:\n",
    "        if tid in map2:\n",
    "            vec2.append(map2[tid])\n",
    "        else:\n",
    "            return float('inf')\n",
    "    \n",
    "    return float(np.linalg.norm(np.array(vec1) - np.array(vec2)))\n",
    "\n",
    "def compare_signals(signals1, signals2, layer_indices):\n",
    "    \"\"\"Compare two signal sets, return distances.\"\"\"\n",
    "    common_positions = set(signals1.keys()) & set(signals2.keys())\n",
    "    \n",
    "    all_key_dists = []\n",
    "    all_logprob_dists = []\n",
    "    \n",
    "    for pos_label in common_positions:\n",
    "        sig1 = signals1[pos_label]['signals'] if 'signals' in signals1[pos_label] else signals1[pos_label]\n",
    "        sig2 = signals2[pos_label]['signals'] if 'signals' in signals2[pos_label] else signals2[pos_label]\n",
    "        \n",
    "        for layer_name in sig1['key_vectors'].keys():\n",
    "            dist = compute_l2_distance(\n",
    "                sig1['key_vectors'][layer_name],\n",
    "                sig2['key_vectors'][layer_name]\n",
    "            )\n",
    "            all_key_dists.append(dist)\n",
    "            \n",
    "        dist = compute_logprob_distance(sig1['logprobs'], sig2['logprobs'])\n",
    "        all_logprob_dists.append(dist)\n",
    "        \n",
    "    return {\n",
    "        'key_vectors_max': max(all_key_dists) if all_key_dists else 0.0,\n",
    "        'key_vectors_mean': np.mean(all_key_dists) if all_key_dists else 0.0,\n",
    "        'logprobs_max': max(all_logprob_dists) if all_logprob_dists else 0.0,\n",
    "        'logprobs_mean': np.mean(all_logprob_dists) if all_logprob_dists else 0.0\n",
    "    }\n",
    "\n",
    "def find_equivalent_pairs(matrix, batch_sizes, threshold=EQUIVALENCE_THRESHOLD):\n",
    "    \"\"\"Find pairs of batch sizes that produce equivalent results (same kernel).\"\"\"\n",
    "    equivalent_pairs = []\n",
    "    n_bs = len(batch_sizes)\n",
    "    \n",
    "    for i in range(n_bs):\n",
    "        for j in range(i + 1, n_bs):\n",
    "            if matrix[i, j] < threshold:\n",
    "                equivalent_pairs.append((batch_sizes[i], batch_sizes[j]))\n",
    "    \n",
    "    return equivalent_pairs\n",
    "\n",
    "def format_kernel_classes(equivalent_pairs, batch_sizes):\n",
    "    \"\"\"Group batch sizes into kernel equivalence classes.\"\"\"\n",
    "    parent = {bs: bs for bs in batch_sizes}\n",
    "    \n",
    "    def find(x):\n",
    "        if parent[x] != x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "    \n",
    "    def union(x, y):\n",
    "        px, py = find(x), find(y)\n",
    "        if px != py:\n",
    "            parent[px] = py\n",
    "    \n",
    "    for bs1, bs2 in equivalent_pairs:\n",
    "        union(bs1, bs2)\n",
    "    \n",
    "    groups = {}\n",
    "    for bs in batch_sizes:\n",
    "        root = find(bs)\n",
    "        if root not in groups:\n",
    "            groups[root] = set()\n",
    "        groups[root].add(bs)\n",
    "    \n",
    "    return list(groups.values())\n",
    "\n",
    "def analyze_within_hardware(measurements, batch_sizes, layer_indices, signal_source='decode'):\n",
    "    \"\"\"Analyze within-hardware batch size effects.\"\"\"\n",
    "    log_print(\"\\n\" + \"=\"*80)\n",
    "    log_print(f\"WITHIN-HARDWARE BATCH SIZE EFFECTS ({signal_source.upper()})\")\n",
    "    log_print(\"=\"*80)\n",
    "    \n",
    "    by_ref = {}\n",
    "    for m in measurements:\n",
    "        ref = m['ref_name']\n",
    "        if ref not in by_ref:\n",
    "            by_ref[ref] = {}\n",
    "        signals_key = 'prefill_signals' if signal_source == 'prefill' else 'decode_signals'\n",
    "        by_ref[ref][m['batch_size']] = m[signals_key]\n",
    "\n",
    "    all_key_matrices = []\n",
    "    all_logprob_matrices = []\n",
    "    n_bs = len(batch_sizes)\n",
    "\n",
    "    for ref_name in sorted(by_ref.keys()):\n",
    "        log_print(f\"\\n{'='*80}\")\n",
    "        log_print(f\"{ref_name.upper()}\")\n",
    "        log_print(\"=\"*80)\n",
    "        \n",
    "        ref_data = by_ref[ref_name]\n",
    "        matrix_key = np.zeros((n_bs, n_bs))\n",
    "        matrix_logprob = np.zeros((n_bs, n_bs))\n",
    "        \n",
    "        for i, bs1 in enumerate(batch_sizes):\n",
    "            for j, bs2 in enumerate(batch_sizes):\n",
    "                if bs1 in ref_data and bs2 in ref_data:\n",
    "                    distances = compare_signals(ref_data[bs1], ref_data[bs2], layer_indices)\n",
    "                    matrix_key[i, j] = distances['key_vectors_mean']\n",
    "                    matrix_logprob[i, j] = distances['logprobs_mean']\n",
    "        \n",
    "        header = \"       \" + \"\".join([f\"bs={bs:>3} \" for bs in batch_sizes])\n",
    "        \n",
    "        log_print(f\"\\nKey Vectors (mean L2 distance):\")\n",
    "        log_print(header)\n",
    "        for i, bs in enumerate(batch_sizes):\n",
    "            row_str = f\"bs={bs:<3}\"\n",
    "            for j in range(n_bs):\n",
    "                row_str += f\"  {matrix_key[i,j]:8.2e}\"\n",
    "            log_print(row_str)\n",
    "            \n",
    "        log_print(f\"\\nLogprobs (mean L2 distance):\")\n",
    "        log_print(header)\n",
    "        for i, bs in enumerate(batch_sizes):\n",
    "            row_str = f\"bs={bs:<3}\"\n",
    "            for j in range(n_bs):\n",
    "                row_str += f\"  {matrix_logprob[i,j]:8.2e}\"\n",
    "            log_print(row_str)\n",
    "            \n",
    "        all_key_matrices.append(matrix_key)\n",
    "        all_logprob_matrices.append(matrix_logprob)\n",
    "\n",
    "    # Aggregate\n",
    "    avg_key_matrix = np.mean(all_key_matrices, axis=0)\n",
    "    avg_logprob_matrix = np.mean(all_logprob_matrices, axis=0)\n",
    "\n",
    "    log_print(f\"\\n{'='*80}\")\n",
    "    log_print(\"AGGREGATE (average across references):\")\n",
    "    log_print(\"=\"*80)\n",
    "\n",
    "    header = \"       \" + \"\".join([f\"bs={bs:>3} \" for bs in batch_sizes])\n",
    "    \n",
    "    log_print(f\"\\nKey Vectors (mean L2 distance):\")\n",
    "    log_print(header)\n",
    "    for i, bs in enumerate(batch_sizes):\n",
    "        row_str = f\"bs={bs:<3}\"\n",
    "        for j in range(n_bs):\n",
    "            row_str += f\"  {avg_key_matrix[i,j]:8.2e}\"\n",
    "        log_print(row_str)\n",
    "\n",
    "    log_print(f\"\\nLogprobs (mean L2 distance):\")\n",
    "    log_print(header)\n",
    "    for i, bs in enumerate(batch_sizes):\n",
    "        row_str = f\"bs={bs:<3}\"\n",
    "        for j in range(n_bs):\n",
    "            row_str += f\"  {avg_logprob_matrix[i,j]:8.2e}\"\n",
    "        log_print(row_str)\n",
    "\n",
    "    off_diag_key = avg_key_matrix[np.triu_indices(n_bs, k=1)]\n",
    "    off_diag_logprob = avg_logprob_matrix[np.triu_indices(n_bs, k=1)]\n",
    "    \n",
    "    key_mean = np.mean(off_diag_key[np.isfinite(off_diag_key)]) if np.any(np.isfinite(off_diag_key)) else 0\n",
    "    logprob_mean = np.mean(off_diag_logprob[np.isfinite(off_diag_logprob)]) if np.any(np.isfinite(off_diag_logprob)) else 0\n",
    "    \n",
    "    log_print(f\"\\nOff-diagonal stats:\")\n",
    "    log_print(f\"  Key vectors - Mean: {key_mean:.2e}, Range: [{np.min(off_diag_key):.2e}, {np.max(off_diag_key):.2e}]\")\n",
    "    log_print(f\"  Logprobs - Mean: {logprob_mean:.2e}, Range: [{np.min(off_diag_logprob):.2e}, {np.max(off_diag_logprob):.2e}]\")\n",
    "\n",
    "    equivalent_pairs = find_equivalent_pairs(avg_key_matrix, batch_sizes)\n",
    "    kernel_classes = format_kernel_classes(equivalent_pairs, batch_sizes)\n",
    "    \n",
    "    zero_count = np.sum(off_diag_key < EQUIVALENCE_THRESHOLD)\n",
    "    total_count = len(off_diag_key)\n",
    "    \n",
    "    if zero_count == total_count:\n",
    "        log_print(f\"\\n⚠ WARNING: {zero_count}/{total_count} comparisons are EXACTLY ZERO\")\n",
    "        log_print(\"  All batch sizes produce identical results (single kernel class)\")\n",
    "    elif zero_count > 0:\n",
    "        log_print(f\"\\n⚠ NOTE: {zero_count}/{total_count} comparisons are equivalent (< {EQUIVALENCE_THRESHOLD})\")\n",
    "    \n",
    "    log_print(f\"\\nKernel equivalence classes:\")\n",
    "    for i, cls in enumerate(kernel_classes):\n",
    "        log_print(f\"  Class {i+1}: {sorted(cls)}\")\n",
    "    \n",
    "    if equivalent_pairs:\n",
    "        log_print(f\"\\nEquivalent pairs (will be excluded from cross-hardware signal):\")\n",
    "        for bs1, bs2 in equivalent_pairs:\n",
    "            log_print(f\"  ({bs1}, {bs2})\")\n",
    "    \n",
    "    threshold = 1e-10\n",
    "    if key_mean > threshold and logprob_mean > threshold:\n",
    "        log_print(\"\\n✓ SANITY CHECK PASSED\")\n",
    "    else:\n",
    "        log_print(\"\\n✗ SANITY CHECK FAILED (No variation)\")\n",
    "        \n",
    "    return {\n",
    "        'key_matrix': avg_key_matrix.tolist(),\n",
    "        'logprob_matrix': avg_logprob_matrix.tolist(),\n",
    "        'per_reference_key_matrices': [m.tolist() for m in all_key_matrices],\n",
    "        'per_reference_logprob_matrices': [m.tolist() for m in all_logprob_matrices],\n",
    "        'key_vectors_mean': float(key_mean),\n",
    "        'logprobs_mean': float(logprob_mean),\n",
    "        'equivalent_pairs': equivalent_pairs,\n",
    "        'kernel_classes': [sorted(list(cls)) for cls in kernel_classes]\n",
    "    }\n",
    "\n",
    "def analyze_cross_hardware_matrix(comparison_results, batch_sizes, layer_indices, \n",
    "                                   signal_source='decode', equivalent_pairs=None):\n",
    "    \"\"\"\n",
    "    Analyze the comparison matrix and determine detectability.\n",
    "    Excludes equivalent pairs from SNR signal calculation.\n",
    "    \"\"\"\n",
    "    log_print(\"\\n\" + \"=\"*80)\n",
    "    log_print(f\"CROSS-HARDWARE BATCH SIZE DETECTABILITY ({signal_source.upper()})\")\n",
    "    log_print(\"=\"*80)\n",
    "    \n",
    "    if equivalent_pairs is None:\n",
    "        equivalent_pairs = []\n",
    "    \n",
    "    equiv_set = set()\n",
    "    for bs1, bs2 in equivalent_pairs:\n",
    "        equiv_set.add((bs1, bs2))\n",
    "        equiv_set.add((bs2, bs1))\n",
    "    \n",
    "    dist_key = 'prefill_distances' if signal_source == 'prefill' else 'decode_distances'\n",
    "    \n",
    "    by_ref = {}\n",
    "    for result in comparison_results:\n",
    "        ref = result['ref_name']\n",
    "        if ref not in by_ref:\n",
    "            by_ref[ref] = {}\n",
    "        key = (result['claimed_batch_size'], result['verify_batch_size'])\n",
    "        by_ref[ref][key] = result\n",
    "\n",
    "    all_key_matrices = []\n",
    "    all_logprob_matrices = []\n",
    "    n_bs = len(batch_sizes)\n",
    "\n",
    "    for ref_name in sorted(by_ref.keys()):\n",
    "        log_print(f\"\\n{'='*80}\")\n",
    "        log_print(f\"{ref_name.upper()}\")\n",
    "        log_print(\"=\"*80)\n",
    "        \n",
    "        ref_data = by_ref[ref_name]\n",
    "        matrix_key = np.zeros((n_bs, n_bs))\n",
    "        matrix_logprob = np.zeros((n_bs, n_bs))\n",
    "        \n",
    "        for i, claimed_bs in enumerate(batch_sizes):\n",
    "            for j, verify_bs in enumerate(batch_sizes):\n",
    "                key = (claimed_bs, verify_bs)\n",
    "                if key in ref_data:\n",
    "                    matrix_key[i, j] = ref_data[key][dist_key]['key_vectors_mean']\n",
    "                    matrix_logprob[i, j] = ref_data[key][dist_key]['logprobs_mean']\n",
    "        \n",
    "        header = \"              \" + \"\".join([f\"v_bs={bs:>3} \" for bs in batch_sizes])\n",
    "        \n",
    "        log_print(f\"\\nKey Vectors (mean L2):\")\n",
    "        log_print(header)\n",
    "        for i, claimed_bs in enumerate(batch_sizes):\n",
    "            row_str = f\"c_bs={claimed_bs:<3} \"\n",
    "            for j in range(n_bs):\n",
    "                row_str += f\"  {matrix_key[i,j]:8.2e}\"\n",
    "            log_print(row_str)\n",
    "        \n",
    "        log_print(f\"\\nLogprobs (mean L2):\")\n",
    "        log_print(header)\n",
    "        for i, claimed_bs in enumerate(batch_sizes):\n",
    "            row_str = f\"c_bs={claimed_bs:<3} \"\n",
    "            for j in range(n_bs):\n",
    "                row_str += f\"  {matrix_logprob[i,j]:8.2e}\"\n",
    "            log_print(row_str)\n",
    "            \n",
    "        all_key_matrices.append(matrix_key)\n",
    "        all_logprob_matrices.append(matrix_logprob)\n",
    "\n",
    "    avg_key_matrix = np.mean(all_key_matrices, axis=0)\n",
    "    avg_logprob_matrix = np.mean(all_logprob_matrices, axis=0)\n",
    "\n",
    "    log_print(f\"\\n{'='*80}\")\n",
    "    log_print(\"AGGREGATE (average across references):\")\n",
    "    log_print(\"=\"*80)\n",
    "\n",
    "    header = \"              \" + \"\".join([f\"v_bs={bs:>3} \" for bs in batch_sizes])\n",
    "    \n",
    "    log_print(f\"\\nKey Vectors (mean L2):\")\n",
    "    log_print(header)\n",
    "    for i, claimed_bs in enumerate(batch_sizes):\n",
    "        row_str = f\"c_bs={claimed_bs:<3} \"\n",
    "        for j in range(n_bs):\n",
    "            row_str += f\"  {avg_key_matrix[i,j]:8.2e}\"\n",
    "        log_print(row_str)\n",
    "\n",
    "    log_print(f\"\\nLogprobs (mean L2):\")\n",
    "    log_print(header)\n",
    "    for i, claimed_bs in enumerate(batch_sizes):\n",
    "        row_str = f\"c_bs={claimed_bs:<3} \"\n",
    "        for j in range(n_bs):\n",
    "            row_str += f\"  {avg_logprob_matrix[i,j]:8.2e}\"\n",
    "        log_print(row_str)\n",
    "\n",
    "    log_print(f\"\\n{'='*80}\")\n",
    "    log_print(\"SNR ANALYSIS\")\n",
    "    log_print(\"=\"*80)\n",
    "\n",
    "    diag_key = np.diag(avg_key_matrix)\n",
    "    diag_logprob = np.diag(avg_logprob_matrix)\n",
    "    diag_key_mean = np.mean(diag_key)\n",
    "    diag_logprob_mean = np.mean(diag_logprob)\n",
    "\n",
    "    log_print(f\"\\nDiagonal (baseline = cross-hardware, same batch size):\")\n",
    "    log_print(f\"  Key vectors: {diag_key_mean:.2e}\")\n",
    "    log_print(f\"  Logprobs: {diag_logprob_mean:.2e}\")\n",
    "\n",
    "    off_diag_key = []\n",
    "    off_diag_logprob = []\n",
    "    for i in range(n_bs):\n",
    "        for j in range(n_bs):\n",
    "            if i != j:\n",
    "                off_diag_key.append(avg_key_matrix[i, j])\n",
    "                off_diag_logprob.append(avg_logprob_matrix[i, j])\n",
    "    \n",
    "    off_diag_key = np.array(off_diag_key)\n",
    "    off_diag_logprob = np.array(off_diag_logprob)\n",
    "    \n",
    "    off_key_mean = np.mean(off_diag_key)\n",
    "    off_logprob_mean = np.mean(off_diag_logprob)\n",
    "    \n",
    "    snr_key = off_key_mean / diag_key_mean if diag_key_mean > 0 else float('inf')\n",
    "    snr_logprob = off_logprob_mean / diag_logprob_mean if diag_logprob_mean > 0 else float('inf')\n",
    "\n",
    "    log_print(f\"\\nOff-diagonal (all pairs):\")\n",
    "    log_print(f\"  Key vectors - Mean: {off_key_mean:.2e}, SNR: {snr_key:.2f}×\")\n",
    "    log_print(f\"  Logprobs - Mean: {off_logprob_mean:.2e}, SNR: {snr_logprob:.2f}×\")\n",
    "\n",
    "    if equivalent_pairs:\n",
    "        log_print(f\"\\nExcluded equivalent pairs (same kernel within-hardware):\")\n",
    "        excluded_count = 0\n",
    "        for bs1, bs2 in equivalent_pairs:\n",
    "            log_print(f\"  ({bs1}, {bs2}) and ({bs2}, {bs1})\")\n",
    "            excluded_count += 2\n",
    "        log_print(f\"  Total excluded: {excluded_count} cells\")\n",
    "        \n",
    "        meaningful_key = []\n",
    "        meaningful_logprob = []\n",
    "        for i in range(n_bs):\n",
    "            for j in range(n_bs):\n",
    "                if i != j:\n",
    "                    bs_i, bs_j = batch_sizes[i], batch_sizes[j]\n",
    "                    if (bs_i, bs_j) not in equiv_set:\n",
    "                        meaningful_key.append(avg_key_matrix[i, j])\n",
    "                        meaningful_logprob.append(avg_logprob_matrix[i, j])\n",
    "        \n",
    "        if meaningful_key:\n",
    "            meaningful_key = np.array(meaningful_key)\n",
    "            meaningful_logprob = np.array(meaningful_logprob)\n",
    "            meaningful_key_mean = np.mean(meaningful_key)\n",
    "            meaningful_logprob_mean = np.mean(meaningful_logprob)\n",
    "            \n",
    "            snr_key_meaningful = meaningful_key_mean / diag_key_mean if diag_key_mean > 0 else float('inf')\n",
    "            snr_logprob_meaningful = meaningful_logprob_mean / diag_logprob_mean if diag_logprob_mean > 0 else float('inf')\n",
    "            \n",
    "            log_print(f\"\\nOff-diagonal (meaningful pairs only):\")\n",
    "            log_print(f\"  Count: {len(meaningful_key)}\")\n",
    "            log_print(f\"  Key vectors - Mean: {meaningful_key_mean:.2e}, SNR: {snr_key_meaningful:.2f}×\")\n",
    "            log_print(f\"  Logprobs - Mean: {meaningful_logprob_mean:.2e}, SNR: {snr_logprob_meaningful:.2f}×\")\n",
    "        else:\n",
    "            snr_key_meaningful = snr_key\n",
    "            snr_logprob_meaningful = snr_logprob\n",
    "    else:\n",
    "        snr_key_meaningful = snr_key\n",
    "        snr_logprob_meaningful = snr_logprob\n",
    "\n",
    "    return {\n",
    "        'key_vectors': {\n",
    "            'diagonal_mean': float(diag_key_mean),\n",
    "            'off_diagonal_mean': float(off_key_mean),\n",
    "            'snr': float(snr_key),\n",
    "            'snr_meaningful': float(snr_key_meaningful)\n",
    "        },\n",
    "        'logprobs': {\n",
    "            'diagonal_mean': float(diag_logprob_mean),\n",
    "            'off_diagonal_mean': float(off_logprob_mean),\n",
    "            'snr': float(snr_logprob),\n",
    "            'snr_meaningful': float(snr_logprob_meaningful)\n",
    "        },\n",
    "        'matrices': {\n",
    "            'key_vectors': avg_key_matrix.tolist(),\n",
    "            'logprobs': avg_logprob_matrix.tolist()\n",
    "        },\n",
    "        'excluded_pairs': equivalent_pairs\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    global REFERENCE_SEQUENCES, DUMMY_SETS\n",
    "    \n",
    "    log_path = setup_logging()\n",
    "    system_info = collect_system_info()\n",
    "    \n",
    "    mode = \"VERIFICATION (teacher-forcing)\" if TEACHER_FORCING else \"GENERATION (reference)\"\n",
    "    log_print(\"=\"*80)\n",
    "    log_print(f\"CROSS-HARDWARE BATCH SIZE DETECTABILITY - {mode}\")\n",
    "    log_print(\"=\"*80)\n",
    "    \n",
    "    log_print(f\"\\nSystem: {system_info['hostname']}\")\n",
    "    log_print(f\"GPU: {system_info['gpu_name']}\")\n",
    "    log_print(f\"Attention: {ATTN_IMPLEMENTATION}\")\n",
    "    log_print(f\"Layers: {LAYER_INDICES}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "    REFERENCE_SEQUENCES, DUMMY_SETS = create_sequences_from_pdf(tokenizer)\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        cache_dir=CACHE_DIR,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=ATTN_IMPLEMENTATION\n",
    "    )\n",
    "    \n",
    "    output_dir = '/workspace/experiments'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if TEACHER_FORCING:\n",
    "        # VERIFICATION MODE\n",
    "        with open(REFERENCE_FILE, 'r') as f:\n",
    "            reference = json.load(f)\n",
    "            \n",
    "        ref_env = reference['metadata']['environment']\n",
    "        validate_environment_match(ref_env, system_info)\n",
    "        \n",
    "        prefill_sanity = reference.get('prefill_sanity_check', {})\n",
    "        decode_sanity = reference.get('decode_sanity_check', {})\n",
    "        \n",
    "        prefill_equiv_pairs = [tuple(p) for p in prefill_sanity.get('equivalent_pairs', [])]\n",
    "        decode_equiv_pairs = [tuple(p) for p in decode_sanity.get('equivalent_pairs', [])]\n",
    "        \n",
    "        log_print(f\"\\nLoaded equivalent pairs from reference:\")\n",
    "        log_print(f\"  Prefill: {prefill_equiv_pairs}\")\n",
    "        log_print(f\"  Decode: {decode_equiv_pairs}\")\n",
    "        \n",
    "        comparison_results = []\n",
    "        ref_by_key = {}\n",
    "        for m in reference['measurements']:\n",
    "            key = (m['ref_name'], m['batch_size'])\n",
    "            ref_by_key[key] = m\n",
    "            \n",
    "        for ref_name in sorted(REFERENCE_SEQUENCES.keys()):\n",
    "            log_print(f\"\\n{'='*80}\")\n",
    "            log_print(f\"REFERENCE: {ref_name}\")\n",
    "            log_print(\"=\"*80)\n",
    "            \n",
    "            for claimed_bs in BATCH_SIZES:\n",
    "                ref_key = (ref_name, claimed_bs)\n",
    "                if ref_key not in ref_by_key:\n",
    "                    log_print(f\"  ⚠ No reference data for {ref_name} bs={claimed_bs}\")\n",
    "                    continue\n",
    "                ref_data = ref_by_key[ref_key]\n",
    "                \n",
    "                log_print(f\"\\n  Claimed batch size: {claimed_bs}\")\n",
    "                \n",
    "                for verify_bs in BATCH_SIZES:\n",
    "                    is_diagonal = (claimed_bs == verify_bs)\n",
    "                    \n",
    "                    log_print(f\"    Verify bs={verify_bs} ({'diag' if is_diagonal else 'off'}):\", end=\"\")\n",
    "                    \n",
    "                    verify_result = run_teacher_forced_decode(\n",
    "                        model, tokenizer, ref_name, ref_data,\n",
    "                        verify_bs, LAYER_INDICES, is_diagonal\n",
    "                    )\n",
    "                    \n",
    "                    prefill_distances = compare_signals(\n",
    "                        ref_data['prefill_signals'], verify_result['prefill_signals'], LAYER_INDICES\n",
    "                    )\n",
    "                    decode_distances = compare_signals(\n",
    "                        ref_data['decode_signals'], verify_result['decode_signals'], LAYER_INDICES\n",
    "                    )\n",
    "                    \n",
    "                    log_print(f\"      Key: {decode_distances['key_vectors_mean']:.2e}, LP: {decode_distances['logprobs_mean']:.2e}\")\n",
    "                    \n",
    "                    comparison_results.append({\n",
    "                        'ref_name': ref_name,\n",
    "                        'claimed_batch_size': claimed_bs,\n",
    "                        'verify_batch_size': verify_bs,\n",
    "                        'prefill_distances': prefill_distances,\n",
    "                        'decode_distances': decode_distances,\n",
    "                    })\n",
    "\n",
    "        prefill_analysis = analyze_cross_hardware_matrix(\n",
    "            comparison_results, BATCH_SIZES, LAYER_INDICES, \n",
    "            signal_source='prefill', equivalent_pairs=prefill_equiv_pairs\n",
    "        )\n",
    "        decode_analysis = analyze_cross_hardware_matrix(\n",
    "            comparison_results, BATCH_SIZES, LAYER_INDICES,\n",
    "            signal_source='decode', equivalent_pairs=decode_equiv_pairs\n",
    "        )\n",
    "        \n",
    "        log_print(\"\\n\" + \"=\"*80)\n",
    "        log_print(\"PREFILL vs DECODE COMPARISON (meaningful SNR)\")\n",
    "        log_print(\"=\"*80)\n",
    "        log_print(f\"Prefill - Key: {prefill_analysis['key_vectors']['snr_meaningful']:.2f}×, LP: {prefill_analysis['logprobs']['snr_meaningful']:.2f}×\")\n",
    "        log_print(f\"Decode  - Key: {decode_analysis['key_vectors']['snr_meaningful']:.2f}×, LP: {decode_analysis['logprobs']['snr_meaningful']:.2f}×\")\n",
    "        \n",
    "        results = {\n",
    "            'metadata': {\n",
    "                'reference_environment': ref_env,\n",
    "                'verifier_environment': system_info,\n",
    "                'batch_sizes': BATCH_SIZES,\n",
    "                'layer_indices': LAYER_INDICES,\n",
    "                'prefill_equivalent_pairs': prefill_equiv_pairs,\n",
    "                'decode_equivalent_pairs': decode_equiv_pairs\n",
    "            },\n",
    "            'comparisons': comparison_results,\n",
    "            'prefill_analysis': prefill_analysis,\n",
    "            'decode_analysis': decode_analysis\n",
    "        }\n",
    "        filepath = os.path.join(output_dir, f\"verify_{timestamp}.json\")\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "            \n",
    "        log_print(f\"\\n✓ Results saved to: {filepath}\")\n",
    "            \n",
    "    else:\n",
    "        # GENERATION MODE\n",
    "        results = {\n",
    "            'metadata': {\n",
    "                'environment': system_info,\n",
    "                'batch_sizes': BATCH_SIZES,\n",
    "                'layer_indices': LAYER_INDICES\n",
    "            },\n",
    "            'measurements': []\n",
    "        }\n",
    "        \n",
    "        for ref_name, ref_token_ids in REFERENCE_SEQUENCES.items():\n",
    "            log_print(f\"\\n{'='*80}\")\n",
    "            log_print(f\"REFERENCE: {ref_name}\")\n",
    "            log_print(\"=\"*80)\n",
    "            \n",
    "            log_print(f\"\\nPrompt length: {len(ref_token_ids)} tokens\\n\")\n",
    "            \n",
    "            for batch_size in BATCH_SIZES:\n",
    "                log_print(f\"  bs={batch_size}:\", end=\"\")\n",
    "                decode_data = run_decode_with_extraction(\n",
    "                    model, tokenizer, ref_token_ids, ref_name, batch_size, LAYER_INDICES\n",
    "                )\n",
    "                results['measurements'].append({\n",
    "                    'ref_name': ref_name,\n",
    "                    'batch_size': batch_size,\n",
    "                    'generated_ids': decode_data['generated_ids'],\n",
    "                    'prompt_token_ids': decode_data['prompt_token_ids'],\n",
    "                    'prefill_signals': decode_data['prefill_signals'],\n",
    "                    'decode_signals': decode_data['decode_signals'],\n",
    "                    'all_batch_generated_ids': decode_data['all_batch_generated_ids']\n",
    "                })\n",
    "        \n",
    "        # Token consistency check\n",
    "        for ref_name in REFERENCE_SEQUENCES.keys():\n",
    "            log_print(f\"\\n--- Token consistency for {ref_name} ---\")\n",
    "            ref_measurements = {m['batch_size']: m for m in results['measurements'] if m['ref_name'] == ref_name}\n",
    "            check_token_consistency(ref_measurements, tokenizer)\n",
    "                \n",
    "        # Within-hardware analysis\n",
    "        prefill_sanity = analyze_within_hardware(\n",
    "            results['measurements'], BATCH_SIZES, LAYER_INDICES, 'prefill'\n",
    "        )\n",
    "        decode_sanity = analyze_within_hardware(\n",
    "            results['measurements'], BATCH_SIZES, LAYER_INDICES, 'decode'\n",
    "        )\n",
    "        \n",
    "        results['prefill_sanity_check'] = prefill_sanity\n",
    "        results['decode_sanity_check'] = decode_sanity\n",
    "        \n",
    "        filepath = os.path.join(output_dir, f\"decode_{timestamp}.json\")\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "            \n",
    "        log_print(f\"\\n✓ Saved to: {filepath}\")\n",
    "        log_print(f\"\\nNext step: Copy to verifier machine, set TEACHER_FORCING=True\")\n",
    "\n",
    "    close_logging()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4face-f066-4ac2-b379-5d6c1a46e210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
